<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="从 CLIP 代码中获得新的灵感"><title>Read Code of CLIP.md</title><link rel=canonical href=https://svtter.cn/p/read-code-of-clip.md/><link rel=stylesheet href=/scss/style.min.c9438dcca76656523c05fa7de95202bf0723cec9aaad0615353bd6699a72adb8.css><meta property='og:title' content="Read Code of CLIP.md"><meta property='og:description' content="从 CLIP 代码中获得新的灵感"><meta property='og:url' content='https://svtter.cn/p/read-code-of-clip.md/'><meta property='og:site_name' content="Svtter's Blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='CLIP'><meta property='article:tag' content='ViT'><meta property='article:tag' content='Deep Learning'><meta property='article:published_time' content='2025-03-19T13:23:50+08:00'><meta property='article:modified_time' content='2025-03-19T13:23:50+08:00'><meta property='og:image' content='https://svtter.cn/p/read-code-of-clip.md/image.png'><meta name=twitter:title content="Read Code of CLIP.md"><meta name=twitter:description content="从 CLIP 代码中获得新的灵感"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://svtter.cn/p/read-code-of-clip.md/image.png'><link rel="shortcut icon" href=/favicon.png><script async src="https://www.googletagmanager.com/gtag/js?id=G-65DJGXT4VC"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-65DJGXT4VC")}</script><script src=https://app.rybbit.io/api/script.js data-site-id=382 defer></script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><header class=site-header><nav class=site-nav><div class=nav-container><a href=/ class=site-brand><span class=brand-name>Svtter's Blog</span></a><div class=nav-links><a href=/%E5%85%B3%E4%BA%8E/ class=nav-link>关于
</a><a href=/archives/ class=nav-link>归档
</a><a href=/search/ class=nav-link>搜索
</a><a href=/%E6%A8%A1%E5%9E%8B/ class=nav-link>模型
</a><a href=/%E9%93%BE%E6%8E%A5/ class=nav-link>链接</a></div><div class=nav-actions><div class=nav-social><a href=https://github.com/svtter target=_blank rel="me noopener" title=GitHub class=social-link><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg>
</a><a href=https://twitter.com/crack_svtter target=_blank rel="me noopener" title=Twitter class=social-link><svg class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg></a></div><a href=/index.xml target=_blank rel=alternate type=application/rss+xml title=RSS class="social-link rss-link"><svg class="icon icon-tabler icon-tabler-rss" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="5" cy="19" r="1" fill="currentColor"/><path d="M4 4a16 16 0 0116 16"/><path d="M4 11a9 9 0 019 9"/></svg>
</a><button id=dark-mode-toggle class=theme-toggle aria-label="Toggle dark mode" title=暗色模式>
<svg class="icon icon-tabler icon-tabler-sun" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="4"/><path d="M3 12h1m8-9v1m8 8h1m-9 8v1M5.6 5.6l.7.7m12.1-.7-.7.7m0 11.4.7.7m-12.1-.7-.7.7"/></svg>
<svg class="icon icon-tabler icon-tabler-moon" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M12 3c.132.0.263.0.393.0a7.5 7.5.0 007.92 12.446A9 9 0 1112 2.992z"/></svg>
</button>
<button class=mobile-menu-toggle id=toggle-menu aria-label="Toggle Menu" aria-expanded=false>
<span class=hamburger-line></span>
<span class=hamburger-line></span>
<span class=hamburger-line></span></button></div></div><div class=mobile-menu id=mobile-menu aria-hidden=true><a href=/%E5%85%B3%E4%BA%8E/ class=mobile-nav-link>关于
</a><a href=/archives/ class=mobile-nav-link>归档
</a><a href=/search/ class=mobile-nav-link>搜索
</a><a href=/%E6%A8%A1%E5%9E%8B/ class=mobile-nav-link>模型
</a><a href=/%E9%93%BE%E6%8E%A5/ class=mobile-nav-link>链接</a><div class=mobile-social><a href=https://github.com/svtter target=_blank rel="me noopener" title=GitHub class=mobile-social-link><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg>
<span>GitHub</span>
</a><a href=https://twitter.com/crack_svtter target=_blank rel="me noopener" title=Twitter class=mobile-social-link><svg class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg>
<span>Twitter</span></a></div></div></nav></header><div class=main-container><main class=main-content><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/read-code-of-clip.md/><img src=/p/read-code-of-clip.md/image_hu_bed4f8999dd62dd3.png srcset="/p/read-code-of-clip.md/image_hu_bed4f8999dd62dd3.png 800w, /p/read-code-of-clip.md/image_hu_10e1dc7e15822af9.png 1600w" width=800 height=282 loading=lazy alt="Featured image of post Read Code of CLIP.md"></a></div><div class=article-details><header class=article-category><a href=/categories/deep-learning/>Deep Learning</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/read-code-of-clip.md/>Read Code of CLIP.md</a></h2><h3 class=article-subtitle>从 CLIP 代码中获得新的灵感</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published datetime=2025-03-19T13:23:50+08:00>Mar 19, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 2 分钟</time></div></footer></div></header><section class=article-content><p>Contrastive Language-Image Pre-Training (CLIP) 是 openai 的经典工作之一。出自论文<a class=link href=https://arxiv.org/abs/2103.00020 target=_blank rel=noopener></a></p><p>为了能够在 CLIP 上完成我的新 idea，我尝试阅读 <a class=link href=https://github.com/openai/CLIP target=_blank rel=noopener>openai/clip</a> 来理解 clip 在 classifier 上的基本工作原理。</p><p>这是 <a class=link href=https://github.com/openai/CLIP target=_blank rel=noopener>openai/clip</a> 给出的 python 样例代码</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>clip</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>device</span> <span class=o>=</span> <span class=s2>&#34;cuda&#34;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&#34;cpu&#34;</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=p>,</span> <span class=n>preprocess</span> <span class=o>=</span> <span class=n>clip</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&#34;ViT-B/32&#34;</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>preprocess</span><span class=p>(</span><span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=s2>&#34;CLIP.png&#34;</span><span class=p>))</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>clip</span><span class=o>.</span><span class=n>tokenize</span><span class=p>([</span><span class=s2>&#34;a diagram&#34;</span><span class=p>,</span> <span class=s2>&#34;a dog&#34;</span><span class=p>,</span> <span class=s2>&#34;a cat&#34;</span><span class=p>])</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>image_features</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>encode_image</span><span class=p>(</span><span class=n>image</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>text_features</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>encode_text</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logits_per_image</span><span class=p>,</span> <span class=n>logits_per_text</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>probs</span> <span class=o>=</span> <span class=n>logits_per_image</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Label probs:&#34;</span><span class=p>,</span> <span class=n>probs</span><span class=p>)</span>  <span class=c1># prints: [[0.9927937  0.00421068 0.00299572]]</span>
</span></span></code></pre></td></tr></table></div></div><p>load 函数用于加载特定的 openai 模型。这里是基于<code>ViT-B/32</code>，一个 Vision Transformer 32B。</p><p>可以看到，如果 openai 支持的 vision encoder 大概有如下几种：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>_MODELS</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;RN50&#34;</span><span class=p>:</span> <span class=s2>&#34;https://openaipublic.azureedge.net/clip/models/afeb0e10f9e5a86da6080e35cf09123aca3b358a0c3e3b6c78a7b63bc04b6762/RN50.pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;RN101&#34;</span><span class=p>:</span> <span class=s2>&#34;https://openaipublic.azureedge.net/clip/models/8fa8567bab74a42d41c5915025a8e4538c3bdbe8804a470a72f30b0d94fab599/RN101.pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;RN50x4&#34;</span><span class=p>:</span> <span class=s2>&#34;https://openaipublic.azureedge.net/clip/models/7e526bd135e493cef0776de27d5f42653e6b4c8bf9e0f653bb11773263205fdd/RN50x4.pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;RN50x16&#34;</span><span class=p>:</span> <span class=s2>&#34;https://openaipublic.azureedge.net/clip/models/52378b407f34354e150460fe41077663dd5b39c54cd0bfd2b27167a4a06ec9aa/RN50x16.pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;RN50x64&#34;</span><span class=p>:</span> <span class=s2>&#34;https://openaipublic.azureedge.net/clip/models/be1cfb55d75a9666199fb2206c106743da0f6468c9d327f3e0d0a543a9919d9c/RN50x64.pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;ViT-B/32&#34;</span><span class=p>:</span> <span class=s2>&#34;https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;ViT-B/16&#34;</span><span class=p>:</span> <span class=s2>&#34;https://openaipublic.azureedge.net/clip/models/5806e77cd80f8b59890b7e101eabd078d9fb84e6937f9e85e4ecb61988df416f/ViT-B-16.pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;ViT-L/14&#34;</span><span class=p>:</span> <span class=s2>&#34;https://openaipublic.azureedge.net/clip/models/b8cca3fd41ae0c99ba7e8951adf17d267cdb84cd88be6f7c2e0eca1737a03836/ViT-L-14.pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;ViT-L/14@336px&#34;</span><span class=p>:</span> <span class=s2>&#34;https://openaipublic.azureedge.net/clip/models/3035c92b350959924f9f00213499208652fc7ea050643e8b385c2dac08641f02/ViT-L-14-336px.pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>我们假设模型已经下载完成，让我们看看 _tranform 预处理工作是如何进行的：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>_transform</span><span class=p>(</span><span class=n>n_px</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>Compose</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=n>Resize</span><span class=p>(</span><span class=n>n_px</span><span class=p>,</span> <span class=n>interpolation</span><span class=o>=</span><span class=n>BICUBIC</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>CenterCrop</span><span class=p>(</span><span class=n>n_px</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>_convert_image_to_rgb</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>ToTensor</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=n>Normalize</span><span class=p>((</span><span class=mf>0.48145466</span><span class=p>,</span> <span class=mf>0.4578275</span><span class=p>,</span> <span class=mf>0.40821073</span><span class=p>),</span> <span class=p>(</span><span class=mf>0.26862954</span><span class=p>,</span> <span class=mf>0.26130258</span><span class=p>,</span> <span class=mf>0.27577711</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>也不是很复杂，预处理<code>Normalize</code>参数虽然不太明白。似乎是用的 ViT 同样的预处理参数。</p><p>然后进入模型加载阶段，我们可以看到，如果不是 <a class=link href=https://chenglu.me/blogs/pytorch-jit target=_blank rel=noopener>jit 加载</a> ，那么模型会选择 state_dict 的模式。
通过加载 state_dict 的过程，我们可以看到 build_model 函数用于加载权重，将权重赋值给已有的模型结构。</p><p>这个模型结构的文件是<a class=link href=https://github.com/openai/CLIP/blob/main/clip/model.py target=_blank rel=noopener>model.py</a>。
因此，CLIP 的主要代码位于<a class=link href=https://github.com/openai/CLIP/blob/main/clip/model.py#L243 target=_blank rel=noopener>model.py#L243</a>。</p><p>image_encoder 和 text_encoder 的输出，分别是两个不同的特征 tensor。</p><p>将两个 tensor 进行矩阵乘积，分别得到一个相似性矩阵。这个相似性矩阵的大小是 <code>(batch_size, batch_size)</code>。</p><blockquote><p>TIPS: 如果说 batch-size 太小，为1，那么对比学习的性能可能就大打折扣了。</p></blockquote><p>这两个 tensor 使用 symmetric cross-entropy loss 进行计算，来用于更新网络权重。</p><p>专门做智能指标的提升，不太在意计算量。不追求最新最高的智能指标，更加关注模型计算的运行效率。</p><blockquote><p>trick: 给参数加一个 log 来使得权重更新没有那么剧烈，计算起来没有那么大。</p></blockquote><p><a class=link href=https://github.com/openai/CLIP target=_blank rel=noopener>CLIP</a> 代码中没有给出能够直接进行训练的代码。下一篇文章，尝试阅读一下 openclip。</p></section><footer class=article-footer><section class=article-tags><a href=/tags/clip/>CLIP</a>
<a href=/tags/vit/>ViT</a>
<a href=/tags/deep-learning/>Deep Learning</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/p/%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%B5%8F%E8%A7%88%E5%92%8C%E5%AD%98%E5%82%A8/><div class=article-details><h2 class=article-title>图片数据集的浏览和存储</h2></div></a></article><article><a href=/p/cnn-size-computing/><div class=article-details><h2 class=article-title>CNN Size Computing</h2></div></a></article><article><a href=/p/kill-ghost-process/><div class=article-details><h2 class=article-title>Kill Ghost Process</h2></div></a></article><article class=has-image><a href=/p/diffusion-model.md/><div class=article-image><img src=/p/diffusion-model.md/noise-dog.4e980902d7fa4a82647bf2182f2c811f_hu_22709112f80b82c0.png width=250 height=150 loading=lazy alt="Featured image of post Diffusion Model.md" data-hash="md5-TpgJAtf6SoJke/IYLyyBHw=="></div><div class=article-details><h2 class=article-title>Diffusion Model.md</h2></div></a></article></div></div></aside><script src=https://utteranc.es/client.js repo=Svtter/svtter.github.io issue-term=pathname label=blog crossorigin=anonymous async></script><style>.utterances{max-width:unset}</style><script>let utterancesLoaded=!1;function setUtterancesTheme(e){let t=document.querySelector(".utterances iframe");t&&t.contentWindow.postMessage({type:"set-theme",theme:`github-${e}`},"https://utteranc.es")}addEventListener("message",e=>{if(e.origin!=="https://utteranc.es")return;utterancesLoaded=!0,setUtterancesTheme(document.documentElement.dataset.scheme)}),window.addEventListener("onColorSchemeChange",e=>{if(!utterancesLoaded)return;setUtterancesTheme(e.detail)})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 Svtter's Blog</section><section class=powerby>主题 <b>Fried Rice</b> 由 <a href=https://svtter.cn target=_blank rel=noopener>svtter</a> 设计<br>Built on <a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener>Stack</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 Svtter's Blog</section><section class=powerby>主题 <b>Fried Rice</b> 由 <a href=https://svtter.cn target=_blank rel=noopener>svtter</a> 设计<br>Built on <a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener>Stack</a></section></footer><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.819d8260de0b0b6a8b97c82ade6b299972e3dd9e2488ad5a3fe6d991e64bc602.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>