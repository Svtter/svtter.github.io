<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tricks on Svtter&#39;s Blog</title>
    <link>/zh-cn/tags/tricks/</link>
    <description>Recent content in Tricks on Svtter&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2016-{year} Hao Xiu. All Rights Reserved.</copyright>
    <lastBuildDate>Mon, 07 Jan 2019 01:00:00 +0800</lastBuildDate><atom:link href="/zh-cn/tags/tricks/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>My Keras tricks.</title>
      <link>/2019/01/07/my-keras-tricks/</link>
      <pubDate>Mon, 07 Jan 2019 01:00:00 +0800</pubDate>
      
      <guid>/2019/01/07/my-keras-tricks/</guid>
      <description>记录了一些使用 keras 的技巧。 categorical_crossentropy vs sparse_categorical_crossentropy. 3. The Answer, In a Nutshell If your targets are one-hot encoded, use categorical_crossentropy. Examples of one-hot encodings: [1,0,0] [0,1,0] [0,0,1] But if your targets are integers, use sparse_categorical_crossentropy. Examples of integer encodings (for the sake of completion): 1, 2, 3 clip norm Multiple GPU # https://keras.io/utils/#multi_gpu_model# 使用多GPU，注</description>
    </item>
    
  </channel>
</rss>
