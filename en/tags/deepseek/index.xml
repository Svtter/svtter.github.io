<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Deepseek on Svtter's Blog</title><link>https://svtter.cn/en/tags/deepseek/</link><description>Recent content in Deepseek on Svtter's Blog</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 14 Oct 2025 10:16:54 +0800</lastBuildDate><atom:link href="https://svtter.cn/en/tags/deepseek/index.xml" rel="self" type="application/rss+xml"/><item><title>Claude Code Plugin Usage Experience</title><link>https://svtter.cn/en/p/claude-code-plugin-usage-experience/</link><pubDate>Tue, 14 Oct 2025 10:16:54 +0800</pubDate><guid>https://svtter.cn/en/p/claude-code-plugin-usage-experience/</guid><description>&lt;img src="https://svtter.cn/p/claude-code-plugin-%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/pics/bg.svg" alt="Featured image of post Claude Code Plugin Usage Experience" /&gt;&lt;p&gt;Overall, the experience was not good.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s likely because it&amp;rsquo;s newly launched and generally feels immature.&lt;/p&gt;
&lt;p&gt;Typical issues include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Not using available &lt;a class="link" href="https://docs.claude.com/en/docs/claude-code/sub-agents#example-subagents" target="_blank" rel="noopener"
&gt;agents&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Not using available &lt;a class="link" href="https://docs.claude.com/en/docs/agents-and-tools/mcp-connector#mcp-server-configuration" target="_blank" rel="noopener"
&gt;MCP&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Tool calls are infrequent and require manual prompting. As a user, I generally don&amp;rsquo;t deliberately memorize which agents are available.&lt;/p&gt;
&lt;p&gt;More importantly, it impacts efficiency.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If using DeepSeek V3.2, its relatively short context length (128K) means it doesn&amp;rsquo;t perform well when there are many tools or MCP connections.&lt;/li&gt;
&lt;li&gt;Plugins often don&amp;rsquo;t improve the tool usage experience; they can actually degrade it. This is because MCP tools and plugins increase the input token count, forcing the model to process more context. Since the computational complexity of transformers is O(n²), any increase in length has a significant negative impact.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In summary, it&amp;rsquo;s not recommended for use at this time.&lt;/p&gt;</description></item><item><title>[Expired] I now use GLM 4.6 more often.</title><link>https://svtter.cn/en/p/expired-i-now-use-glm-4.6-more-often./</link><pubDate>Thu, 09 Oct 2025 15:36:00 +0800</pubDate><guid>https://svtter.cn/en/p/expired-i-now-use-glm-4.6-more-often./</guid><description>&lt;img src="https://svtter.cn/p/%E8%BF%87%E6%9C%9F-%E6%88%91%E7%8E%B0%E5%9C%A8%E6%9B%B4%E5%A4%9A%E7%9A%84%E4%BD%BF%E7%94%A8-glm-4.6-%E4%BA%86/glm-vs-deepseek.svg" alt="Featured image of post [Expired] I now use GLM 4.6 more often." /&gt;&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;● Update&lt;span class="o"&gt;(&lt;/span&gt;content/post/2025-10-24-我又买了-kimi-coding-plan/pics/bg.svg&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; ⎿ Error editing file
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; ⎿ Interrupted · What should Claude &lt;span class="k"&gt;do&lt;/span&gt; instead?
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;updated at: 2025-10-27
I only use glm4.6 for very simple tasks. In practical experience, minor issues frequently arise. For example, when using claude code, it is unable to update files. Here are some recent experiences using code agents.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id="model-comparison"&gt;Model Comparison
&lt;/h2&gt;&lt;p&gt;Based on my practical usage, GLM 4.6 is still slightly stronger than DeepSeek v3.2.&lt;/p&gt;
&lt;p&gt;For example, in a Next.js project, I configured &lt;code&gt;nextjs config -&amp;gt; baseUrl 192.168.2.14:8080&lt;/code&gt;. GLM 4.6 was able to recognize this pre-configured setting without explicit context, whereas DeepSeek v3.2 could not.&lt;/p&gt;
&lt;p&gt;However, GLM 4.6 is not superior in all aspects. When dealing with relatively ambiguous problems, DeepSeek v3.2 is more conservative and does not violate the constraints I set before task completion. In contrast, GLM 4.6 tends to ignore my constraints, makes bold modifications, and ends up breaking things.&lt;/p&gt;
&lt;h2 id="tools"&gt;Tools
&lt;/h2&gt;&lt;p&gt;Compared to using GLM 4.6 in Claude Code / Cline, the experience in Kilo Code is the best.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kilo Code can read files in parallel, while CC can only read them one by one.&lt;/li&gt;
&lt;li&gt;Kilo Code enforces the generation of a plan, imposing more restrictions on the big model compared to CC.&lt;/li&gt;
&lt;li&gt;The visual interface is more user-friendly. I can directly ban Python commands (I need to execute &lt;code&gt;uv run&lt;/code&gt; instead of directly running Python commands).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, Kilo Code itself also has issues. It cannot use MCP servers of the &lt;code&gt;input; http&lt;/code&gt; type, which prevents the use of &lt;code&gt;web-search-prime&lt;/code&gt; on Kilo Code.&lt;/p&gt;
&lt;h2 id="related-reading"&gt;Related Reading
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="link" href="https://atbug.com/budget-efficiency-kilo-code-choice/" target="_blank" rel="noopener"
&gt;Limited Budget, Maximized Efficiency: Why Kilo Code Became My Preferred Coding Agent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="link" href="https://kilocode.ai/" target="_blank" rel="noopener"
&gt;Kilo Code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>How to Use Claude Code With Deepseek</title><link>https://svtter.cn/en/p/how-to-use-claude-code-with-deepseek/</link><pubDate>Tue, 26 Aug 2025 14:42:54 +0800</pubDate><guid>https://svtter.cn/en/p/how-to-use-claude-code-with-deepseek/</guid><description>&lt;img src="https://svtter.cn/p/how-to-use-claude-code-with-deepseek/pics/bg.png" alt="Featured image of post How to Use Claude Code With Deepseek" /&gt;&lt;p&gt;Sometimes we cannot directly use the Anthropic API. However, the Claude Code (CC) experience is excellent, and we still want to use CC.&lt;/p&gt;
&lt;p&gt;In such cases, you can try using the API provided by DeepSeek to access CC.&lt;/p&gt;
&lt;p&gt;DeepSeek has already provided the corresponding interface: &lt;a class="link" href="https://api-docs.deepseek.com/zh-cn/guides/anthropic_api" target="_blank" rel="noopener"
&gt;How to Use the Claude Code + DeepSeek Combination?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Currently, there are two mainstream LLM APIs: one is OpenAI, and the other is Anthropic. Anthropic has gained a certain level of influence through CC.&lt;/p&gt;
&lt;p&gt;If you want to learn more about the use cases for CC, I recommend reading &lt;a class="link" href="https://www.anthropic.com/news/how-anthropic-teams-use-claude-code" target="_blank" rel="noopener"
&gt;Anthropic&amp;rsquo;s Official Blog&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Additionally, here are some supplementary resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class="link" href="https://mp.weixin.qq.com/s/gk0tzMxWZ-NgsUWg5iLoSg" target="_blank" rel="noopener"
&gt;https://mp.weixin.qq.com/s/gk0tzMxWZ-NgsUWg5iLoSg&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item></channel></rss>