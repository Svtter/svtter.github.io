<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LVM on Svtter's Blog</title><link>https://svtter.cn/categories/lvm/</link><description>Recent content in LVM on Svtter's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Fri, 06 Jun 2025 09:56:20 +0800</lastBuildDate><atom:link href="https://svtter.cn/categories/lvm/index.xml" rel="self" type="application/rss+xml"/><item><title>Using Vision Language Model to Perform Meter Reading</title><link>https://svtter.cn/p/using-vision-language-model-to-perform-meter-reading/</link><pubDate>Fri, 06 Jun 2025 09:56:20 +0800</pubDate><guid>https://svtter.cn/p/using-vision-language-model-to-perform-meter-reading/</guid><description>&lt;img src="https://svtter.cn/p/using-vision-language-model-to-perform-meter-reading/bg.png" alt="Featured image of post Using Vision Language Model to Perform Meter Reading" /&gt;&lt;p&gt;除了图片较为复杂的情况，大模型已经能够比较好的识别图像中的文本了。
但是对于一些相对极端的情况，做的还不是很好:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;例如表盘上有水滴，导致图像产生了部分畸变。&lt;/li&gt;
&lt;li&gt;表盘中的分割线太粗，导致模型认为粗线是数字”1”。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这是一个简单的示例，如何通过大模型来进行仪表识别。&lt;/p&gt;
&lt;script src="https://tarptaeya.github.io/repo-card/repo-card.js"&gt;&lt;/script&gt;
&lt;!-- inside body, where you want to create the card --&gt;
&lt;div class="repo-card" data-repo="svtter/vl-model"&gt;&lt;/div&gt;
&lt;p&gt;在这个开源项目里，我调用了兼容 openai 接口的 qwen 模型，来获取仪表识别的结果。&lt;/p&gt;
&lt;p&gt;尽管模型的性能可能不如想象的好，但是用于主动学习来标注模型绰绰有余。&lt;/p&gt;</description></item></channel></rss>