<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>VLM on Svtter's Blog</title><link>https://svtter.cn/categories/vlm/</link><description>Recent content in VLM on Svtter's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Thu, 19 Jun 2025 16:34:32 +0800</lastBuildDate><atom:link href="https://svtter.cn/categories/vlm/index.xml" rel="self" type="application/rss+xml"/><item><title>Poor Performance of Large Models on Specific Tasks</title><link>https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/</link><pubDate>Thu, 19 Jun 2025 16:34:32 +0800</pubDate><guid>https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/</guid><description>&lt;img src="https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/pics/bg.png" alt="Featured image of post Poor Performance of Large Models on Specific Tasks" />&lt;p>视觉大模型在一些具体任务上比较糟糕，对于格式化的文本比较友好。&lt;/p>
&lt;h2 id="源代码">源代码
&lt;/h2>&lt;p>&lt;a class="link" href="https://github.com/Svtter/vl-model/pull/4" target="_blank" rel="noopener"
>https://github.com/Svtter/vl-model/pull/4&lt;/a>&lt;/p>
&lt;h2 id="测试的文件">测试的文件
&lt;/h2>&lt;p>&lt;img src="https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/pics/meter-2.jpg"
width="1280"
height="1707"
srcset="https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/pics/meter-2_hu_c88be12cb06d2945.jpg 480w, https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/pics/meter-2_hu_791a35b85a8e04bb.jpg 1024w"
loading="lazy"
alt="Original Meter"
class="gallery-image"
data-flex-grow="74"
data-flex-basis="179px"
>&lt;/p>
&lt;p>我们可以从这个测试结果中看出不同模型的表现差异：&lt;/p>
&lt;h2 id="测试结果对比">测试结果对比
&lt;/h2>&lt;h3 id="整体测试结果">整体测试结果
&lt;/h3>&lt;p>&lt;img src="https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/pics/cropped_image.png"
width="1280"
height="1707"
srcset="https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/pics/cropped_image_hu_21b7440b53011ad6.png 480w, https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/pics/cropped_image_hu_e002cc344d0e25da.png 1024w"
loading="lazy"
alt="整体测试结果"
class="gallery-image"
data-flex-grow="74"
data-flex-basis="179px"
>&lt;/p>
&lt;h3 id="各模型详细表现">各模型详细表现
&lt;/h3>&lt;h4 id="anthropic-claude-35-sonnet">Anthropic Claude 3.5 Sonnet
&lt;/h4>&lt;p>&lt;img src="https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/pics/cropped_image_anthropic_claude-3.5-sonnet.png"
width="187"
height="56"
srcset="https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/pics/cropped_image_anthropic_claude-3.5-sonnet_hu_21e838496ec13e0c.png 480w, https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/pics/cropped_image_anthropic_claude-3.5-sonnet_hu_98d3433b78049bde.png 1024w"
loading="lazy"
alt="Claude 3.5 Sonnet 测试结果"
class="gallery-image"
data-flex-grow="333"
data-flex-basis="801px"
>&lt;/p>
&lt;h4 id="google-gemini-25-pro">Google Gemini 2.5 Pro
&lt;/h4>&lt;p>&lt;img src="https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/pics/cropped_image_google_gemini-2.5-pro.png"
width="690"
height="142"
srcset="https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/pics/cropped_image_google_gemini-2.5-pro_hu_eb7a36a86550fa2e.png 480w, https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/pics/cropped_image_google_gemini-2.5-pro_hu_c6c68f3c0be13424.png 1024w"
loading="lazy"
alt="Gemini 2.5 Pro 测试结果"
class="gallery-image"
data-flex-grow="485"
data-flex-basis="1166px"
>&lt;/p>
&lt;h4 id="openai-gpt-4o">OpenAI GPT-4o
&lt;/h4>&lt;p>&lt;img src="https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/pics/cropped_image_openai_gpt-4o.png"
width="120"
height="60"
srcset="https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/pics/cropped_image_openai_gpt-4o_hu_66da02220ce9dd8e.png 480w, https://svtter.cn/p/poor-performance-of-large-models-on-specific-tasks/pics/cropped_image_openai_gpt-4o_hu_895477318e72aaf7.png 1024w"
loading="lazy"
alt="GPT-4o 测试结果"
class="gallery-image"
data-flex-grow="200"
data-flex-basis="480px"
>&lt;/p>
&lt;h2 id="分析总结">分析总结
&lt;/h2>&lt;p>从这些测试结果可以看出：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>视觉识别能力差异&lt;/strong>：不同模型在处理相同视觉任务时表现出明显的性能差异&lt;/li>
&lt;li>&lt;strong>格式化文本处理&lt;/strong>：相比视觉任务，模型在处理结构化文本时表现更加稳定&lt;/li>
&lt;li>&lt;strong>模型特性&lt;/strong>：每个模型都有其独特的优势和局限性&lt;/li>
&lt;/ol>
&lt;p>这些结果提醒我们在选择 AI 模型时需要根据具体任务类型来评估其适用性。&lt;/p></description></item></channel></rss>