<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Coding on Svtter's Blog</title><link>https://svtter.cn/tags/coding/</link><description>Recent content in Coding on Svtter's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Fri, 23 Jan 2026 11:52:52 +0800</lastBuildDate><atom:link href="https://svtter.cn/tags/coding/index.xml" rel="self" type="application/rss+xml"/><item><title>大模型 Coding Plan 套餐的数学陷阱：并发限制下的承诺量能否兑现？</title><link>https://svtter.cn/p/%E5%A4%A7%E6%A8%A1%E5%9E%8B-coding-plan-%E5%A5%97%E9%A4%90%E7%9A%84%E6%95%B0%E5%AD%A6%E9%99%B7%E9%98%B1%E5%B9%B6%E5%8F%91%E9%99%90%E5%88%B6%E4%B8%8B%E7%9A%84%E6%89%BF%E8%AF%BA%E9%87%8F%E8%83%BD%E5%90%A6%E5%85%91%E7%8E%B0/</link><pubDate>Fri, 23 Jan 2026 11:52:52 +0800</pubDate><guid>https://svtter.cn/p/%E5%A4%A7%E6%A8%A1%E5%9E%8B-coding-plan-%E5%A5%97%E9%A4%90%E7%9A%84%E6%95%B0%E5%AD%A6%E9%99%B7%E9%98%B1%E5%B9%B6%E5%8F%91%E9%99%90%E5%88%B6%E4%B8%8B%E7%9A%84%E6%89%BF%E8%AF%BA%E9%87%8F%E8%83%BD%E5%90%A6%E5%85%91%E7%8E%B0/</guid><description>&lt;img src="https://svtter.cn/p/%E5%A4%A7%E6%A8%A1%E5%9E%8B-coding-plan-%E5%A5%97%E9%A4%90%E7%9A%84%E6%95%B0%E5%AD%A6%E9%99%B7%E9%98%B1%E5%B9%B6%E5%8F%91%E9%99%90%E5%88%B6%E4%B8%8B%E7%9A%84%E6%89%BF%E8%AF%BA%E9%87%8F%E8%83%BD%E5%90%A6%E5%85%91%E7%8E%B0/cover.png" alt="Featured image of post 大模型 Coding Plan 套餐的数学陷阱：并发限制下的承诺量能否兑现？" /&gt;&lt;h2 id="前言"&gt;前言
&lt;/h2&gt;&lt;p&gt;最近，国内多家大模型厂商纷纷推出面向开发者的 Coding Plan 订阅套餐，主打&amp;quot;低价享受海量用量&amp;quot;，宣称每月仅需几十到几百元，即可获得&amp;quot;数百亿 tokens&amp;quot;的使用额度。&lt;/p&gt;
&lt;p&gt;听起来很美好，但作为一个习惯用数据说话的开发者，我决定算一笔账：&lt;strong&gt;在并发限制下，这些承诺的用量真的能用完吗？&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id="典型套餐结构"&gt;典型套餐结构
&lt;/h2&gt;&lt;p&gt;以市面上常见的三档套餐为例：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;套餐&lt;/th&gt;
&lt;th&gt;月费&lt;/th&gt;
&lt;th&gt;承诺用量（每 5 小时）&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Lite&lt;/td&gt;
&lt;td&gt;~20 元&lt;/td&gt;
&lt;td&gt;约 120 次 prompts&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pro&lt;/td&gt;
&lt;td&gt;~100 元&lt;/td&gt;
&lt;td&gt;约 600 次 prompts&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Max&lt;/td&gt;
&lt;td&gt;~200 元&lt;/td&gt;
&lt;td&gt;约 2,400 次 prompts&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;官方还会补充说明：&amp;ldquo;每次 prompt 预计可调用模型 15-20 次，每月总计可用总量高达几十亿到数百亿 tokens。&amp;rdquo;&lt;/p&gt;
&lt;p&gt;看起来性价比爆表，但魔鬼藏在细节里。&lt;/p&gt;
&lt;h2 id="关键限制并发数"&gt;关键限制：并发数
&lt;/h2&gt;&lt;p&gt;大多数厂商的文档中会轻描淡写地提到：&amp;ldquo;套餐使用受到并发数（在途请求任务数量）的限制。&amp;rdquo;&lt;/p&gt;
&lt;p&gt;但具体是多少？往往不会明确告知。根据社区反馈和实测，典型的并发限制如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;套餐&lt;/th&gt;
&lt;th&gt;并发数（在途请求）&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Lite&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pro&lt;/td&gt;
&lt;td&gt;~4-5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Max&lt;/td&gt;
&lt;td&gt;~7&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这个数字，直接决定了你的实际吞吐量上限。&lt;/p&gt;
&lt;h2 id="数学时间max-套餐能否用完-2400-prompts"&gt;数学时间：Max 套餐能否用完 2,400 prompts？
&lt;/h2&gt;&lt;p&gt;让我们以最高档的 Max 套餐为例，做一个简单的计算。&lt;/p&gt;
&lt;h3 id="已知条件"&gt;已知条件
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;承诺用量&lt;/strong&gt;：每 5 小时 2,400 次 prompts&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;并发限制&lt;/strong&gt;：7&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;每 prompt 触发的模型调用次数&lt;/strong&gt;：15-20 次（官方数据）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;模型生成速度&lt;/strong&gt;：约 50-60 tokens/秒&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;5 小时 = 18,000 秒&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="计算过程"&gt;计算过程
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Step 1：估算单次 API 调用耗时&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一次完整的 API 调用包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入处理：~1 秒&lt;/li&gt;
&lt;li&gt;模型推理生成（假设输出 500 tokens）：500 ÷ 55 ≈ 9 秒&lt;/li&gt;
&lt;li&gt;网络往返延迟：~1 秒&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;合计：约 10-12 秒/次调用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 2：计算 5 小时内的最大调用次数&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-fallback" data-lang="fallback"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;最大调用次数 = 并发数 × (总时间 ÷ 单次耗时)
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; = 7 × (18,000 ÷ 10)
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; = 12,600 次
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Step 3：换算为 prompts 数量&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;按官方说法，每 prompt 触发 15-20 次调用：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-fallback" data-lang="fallback"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;可完成 prompts = 12,600 ÷ 17.5 ≈ 720 次
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id="结论"&gt;结论
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;指标&lt;/th&gt;
&lt;th&gt;官方承诺&lt;/th&gt;
&lt;th&gt;并发上限&lt;/th&gt;
&lt;th&gt;达成率&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;每 5 小时 prompts&lt;/td&gt;
&lt;td&gt;2,400&lt;/td&gt;
&lt;td&gt;~720&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;30%&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;即使在理想条件下，Max 套餐的实际可用量也只有承诺的 30% 左右。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id="更残酷的现实agent-模式下的调用膨胀"&gt;更残酷的现实：Agent 模式下的调用膨胀
&lt;/h2&gt;&lt;p&gt;上面的计算还是基于官方宣称的&amp;quot;每 prompt 15-20 次调用&amp;quot;。但在实际的 AI Coding Agent（如 Claude Code、Cline 等）场景中，情况要糟糕得多。&lt;/p&gt;
&lt;h3 id="agent-模式的工作方式"&gt;Agent 模式的工作方式
&lt;/h3&gt;&lt;p&gt;当你给 AI 编程助手一个任务时，它通常会：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;分析需求，制定计划&lt;/li&gt;
&lt;li&gt;读取相关文件（每个文件可能触发一次调用）&lt;/li&gt;
&lt;li&gt;编写代码&lt;/li&gt;
&lt;li&gt;运行测试&lt;/li&gt;
&lt;li&gt;发现错误，修复&lt;/li&gt;
&lt;li&gt;重复 3-5 直到成功&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;一个看似简单的 prompt，在 Agent 循环中可能触发 &lt;strong&gt;50-100+ 次模型调用&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id="实测案例"&gt;实测案例
&lt;/h3&gt;&lt;p&gt;有用户反馈：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;2 条简单 prompt，80 秒，消耗 38M Tokens，用掉 97% 的 5 小时限额&amp;rdquo;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;反推计算：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个 prompt 消耗约 19M tokens&lt;/li&gt;
&lt;li&gt;如果按 128K 上下文计算，相当于 &lt;strong&gt;~127 次模型调用/prompt&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这比官方说的&amp;quot;15-20 次&amp;quot;高出 &lt;strong&gt;6-8 倍&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id="修正后的实际可用量"&gt;修正后的实际可用量
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;场景&lt;/th&gt;
&lt;th&gt;每 prompt 调用次数&lt;/th&gt;
&lt;th&gt;5 小时可用 prompts&lt;/th&gt;
&lt;th&gt;达成率&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;官方理想值&lt;/td&gt;
&lt;td&gt;17.5&lt;/td&gt;
&lt;td&gt;720&lt;/td&gt;
&lt;td&gt;30%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;轻度使用&lt;/td&gt;
&lt;td&gt;50&lt;/td&gt;
&lt;td&gt;252&lt;/td&gt;
&lt;td&gt;10.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;中度使用&lt;/td&gt;
&lt;td&gt;75&lt;/td&gt;
&lt;td&gt;168&lt;/td&gt;
&lt;td&gt;7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;重度 Agent&lt;/td&gt;
&lt;td&gt;100+&lt;/td&gt;
&lt;td&gt;&amp;lt;126&lt;/td&gt;
&lt;td&gt;&amp;lt;5%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id="为什么会这样"&gt;为什么会这样？
&lt;/h2&gt;&lt;h3 id="1-token-计算包含-context"&gt;1. Token 计算包含 Context
&lt;/h3&gt;&lt;p&gt;大模型的 token 消耗不仅仅是输出，还包括输入。在 Coding 场景下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每次调用都要发送完整的对话历史&lt;/li&gt;
&lt;li&gt;代码项目的上下文动辄几十 K tokens&lt;/li&gt;
&lt;li&gt;128K 上下文窗口意味着每次调用可能消耗 100K+ tokens&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="2-并发是硬约束"&gt;2. 并发是硬约束
&lt;/h3&gt;&lt;p&gt;无论你的套餐额度有多大，并发数决定了单位时间内的最大吞吐量。这是一个&lt;strong&gt;物理瓶颈&lt;/strong&gt;，不是商业策略能绕过的。&lt;/p&gt;
&lt;h3 id="3-承诺基于理想假设"&gt;3. 承诺基于理想假设
&lt;/h3&gt;&lt;p&gt;厂商的宣传数字，往往基于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每次调用只用很小的 context&lt;/li&gt;
&lt;li&gt;每个 prompt 只触发少量调用&lt;/li&gt;
&lt;li&gt;用户不会连续高强度使用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但这些假设在真实的 AI Coding 场景中几乎不成立。&lt;/p&gt;
&lt;h2 id="一张表看清真相"&gt;一张表看清真相
&lt;/h2&gt;&lt;p&gt;以 Max 套餐（~200 元/月）为例：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;指标&lt;/th&gt;
&lt;th&gt;官方宣传&lt;/th&gt;
&lt;th&gt;理论上限&lt;/th&gt;
&lt;th&gt;实际预期&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;每 5 小时 prompts&lt;/td&gt;
&lt;td&gt;2,400&lt;/td&gt;
&lt;td&gt;720&lt;/td&gt;
&lt;td&gt;150-400&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;每月 prompts&lt;/td&gt;
&lt;td&gt;345,600&lt;/td&gt;
&lt;td&gt;103,680&lt;/td&gt;
&lt;td&gt;21,600-57,600&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;每月 tokens&lt;/td&gt;
&lt;td&gt;&amp;ldquo;数百亿&amp;rdquo;&lt;/td&gt;
&lt;td&gt;~100 亿&lt;/td&gt;
&lt;td&gt;10-30 亿&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;达成率&lt;/td&gt;
&lt;td&gt;100%&lt;/td&gt;
&lt;td&gt;30%&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;5-17%&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id="给开发者的建议"&gt;给开发者的建议
&lt;/h2&gt;&lt;h3 id="1-别被数百亿-tokens忽悠"&gt;1. 别被&amp;quot;数百亿 tokens&amp;quot;忽悠
&lt;/h3&gt;&lt;p&gt;Token 数量是一个极具误导性的指标。在 Coding Agent 场景下，context 占了大头，真正有效的输出 tokens 可能只有 1-5%。&lt;/p&gt;
&lt;h3 id="2-关注并发数"&gt;2. 关注并发数
&lt;/h3&gt;&lt;p&gt;这才是决定实际体验的核心指标。如果厂商不公开并发限制，大概率是因为数字不好看。&lt;/p&gt;
&lt;h3 id="3-计算单-prompt-成本"&gt;3. 计算单 prompt 成本
&lt;/h3&gt;&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-fallback" data-lang="fallback"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;实际单 prompt 成本 = 月费 ÷ 实际可用 prompts
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;以 Max 套餐为例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;官方宣传：200 ÷ 345,600 = 0.0006 元/prompt&lt;/li&gt;
&lt;li&gt;实际情况：200 ÷ 30,000 = &lt;strong&gt;0.007 元/prompt&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;差了 10 倍。&lt;/p&gt;
&lt;h3 id="4-考虑按量付费"&gt;4. 考虑按量付费
&lt;/h3&gt;&lt;p&gt;如果你的使用量不大，按量付费可能比包月更划算。至少不会为&amp;quot;用不完的额度&amp;quot;买单。&lt;/p&gt;
&lt;h2 id="结语"&gt;结语
&lt;/h2&gt;&lt;p&gt;大模型 Coding Plan 套餐的出现本身是好事，降低了开发者使用 AI 编程助手的门槛。但在选择套餐时，请务必：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;要求厂商公开并发限制&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;自己动手算一算吞吐量上限&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;不要被&amp;quot;数百亿 tokens&amp;quot;的大数字迷惑&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;毕竟，&lt;strong&gt;承诺的用量用不完，就等于变相涨价&lt;/strong&gt;。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;本文基于公开信息和数学推导，具体数值可能因厂商调整而变化。建议读者以实测为准。&lt;/em&gt;&lt;/p&gt;</description></item><item><title>通过 spec kit 加强弱模型的表现</title><link>https://svtter.cn/p/%E9%80%9A%E8%BF%87-spec-kit-%E5%8A%A0%E5%BC%BA%E5%BC%B1%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8E%B0/</link><pubDate>Fri, 14 Nov 2025 15:41:46 +0800</pubDate><guid>https://svtter.cn/p/%E9%80%9A%E8%BF%87-spec-kit-%E5%8A%A0%E5%BC%BA%E5%BC%B1%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8E%B0/</guid><description>&lt;img src="https://svtter.cn/p/%E9%80%9A%E8%BF%87-spec-kit-%E5%8A%A0%E5%BC%BA%E5%BC%B1%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8E%B0/pics/bg.png" alt="Featured image of post 通过 spec kit 加强弱模型的表现" /&gt;&lt;blockquote&gt;
&lt;p&gt;又是一篇如何止损 glm4.6 的文章。我们的老朋友 glm 4.6。新朋友 doubao-seed-code 也来了。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a class="link" href="https://github.com/github/spec-kit" target="_blank" rel="noopener"
&gt;github spec-kit&lt;/a&gt; 是 github 推出的一个 coding agent 加强工具，旨在让工程更加规范化和容易。&lt;/p&gt;
&lt;p&gt;本来我对此不屑一顾，反正我有 claude code max plan，还用它作甚。然后：&lt;/p&gt;
&lt;p&gt;&lt;img src="https://svtter.cn/p/%E9%80%9A%E8%BF%87-spec-kit-%E5%8A%A0%E5%BC%BA%E5%BC%B1%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8E%B0/pics/limit.png"
width="2118"
height="126"
srcset="https://svtter.cn/p/%E9%80%9A%E8%BF%87-spec-kit-%E5%8A%A0%E5%BC%BA%E5%BC%B1%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8E%B0/pics/limit_hu_d5a32301f7e47a36.png 480w, https://svtter.cn/p/%E9%80%9A%E8%BF%87-spec-kit-%E5%8A%A0%E5%BC%BA%E5%BC%B1%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8E%B0/pics/limit_hu_5d241018e40f9047.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="1680"
data-flex-basis="4034px"
&gt;&lt;/p&gt;
&lt;p&gt;实际上也是用了 spec kit 的结果，导致 token 消耗量巨大。否则按照我平时的使用量，应该是刚刚好才对。&lt;/p&gt;
&lt;p&gt;也就是说便宜模型用起来反而比较划算。因为能力弱，通过大量的 spec 来约束行为，可能表现出比之前更好的性能。&lt;/p&gt;
&lt;p&gt;让我们尝试一下 &lt;a class="link" href="https://github.com/github/spec-kit" target="_blank" rel="noopener"
&gt;spec-kit&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id="安装"&gt;安装
&lt;/h2&gt;&lt;p&gt;安装方面， 建议两条腿走路。&lt;/p&gt;
&lt;p&gt;一个是直接用，不管太多安装的事情：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;uvx --from git+https://github.com/github/spec-kit.git specify init . --github-token&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$GITHUB_TOKEN&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这里的 &lt;code&gt;GITHUB_TOKEN&lt;/code&gt; 指的是 github personal token。&lt;/p&gt;
&lt;p&gt;另外一种则是安装后再使用。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;pipx install git+https://github.com/github/spec-kit.git
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;各有利弊。前者无需安装，但每次都要从 git 拉取；后者安装一次即可，但需要管理依赖。&lt;/p&gt;
&lt;h2 id="specification-driven-development"&gt;specification driven development
&lt;/h2&gt;&lt;p&gt;SDD 是最新兴起的一个概念。通过大量的约束来让 coding agent 写出 production-ready 的代码。&lt;/p&gt;
&lt;p&gt;这篇文章讲得不错：&lt;/p&gt;
&lt;a href="https://mp.weixin.qq.com/s/zVvkSCFiknLZcolKjYLoIA" target="_blank" rel="noopener" style="text-decoration:none; display:block; max-width:600px; border: 1px solid #e0e0e0; border-radius:8px; overflow:hidden; color:inherit; font-family:-apple-system, BlinkMacSystemFont, sans-serif; margin:1em 0;"&gt;
&lt;div style="position:relative; padding-top:56.25%; background:#f0f0f0;"&gt;
&lt;!-- 封面图示例：建议替换为实际封面图 URL --&gt;
&lt;img src="pics/sdd.jpg" alt="文章封面" style="position:absolute; top:0; left:0; width:100%; height:100%; object-fit:cover;"&gt;
&lt;/div&gt;
&lt;div style="padding:12px;"&gt;
&lt;h3 style="margin:0 0 8px; font-size:18px; line-height:1.2; color:#000"&gt;
Spec-Driven Development 两个月后的跟进：spec-kit 及生态发展调研
&lt;/h3&gt;
&lt;p style="margin:0 0 10px; color:#555; font-size:14px; line-height:1.4;"&gt;
本文跟进调研了GitHub推出的spec-kit项目在发布两个月后的快速发展，包括其社区增长、功能迭代及生态现状。文章还探讨了规格驱动开发（SDD）这一新兴方法论的核心理念、主要工具对比、面临的挑战以及2025年的行业趋势，为开发者提供了实践建议与展望。
&lt;/p&gt;
&lt;div style="font-size:12px; color:#999;"&gt;
微信公众号 · 发布日期
&lt;/div&gt;
&lt;/div&gt;
&lt;/a&gt;
&lt;p&gt;基于 SDD 的理念，我决定用 spec-kit 来测试弱模型的表现。测试任务是：为 hugo-admin 添加一个发布按钮。&lt;/p&gt;
&lt;p&gt;很遗憾，性能还是不怎么达标。比较好笑的是，中间输出的内容：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt; 1
&lt;/span&gt;&lt;span class="lnt"&gt; 2
&lt;/span&gt;&lt;span class="lnt"&gt; 3
&lt;/span&gt;&lt;span class="lnt"&gt; 4
&lt;/span&gt;&lt;span class="lnt"&gt; 5
&lt;/span&gt;&lt;span class="lnt"&gt; 6
&lt;/span&gt;&lt;span class="lnt"&gt; 7
&lt;/span&gt;&lt;span class="lnt"&gt; 8
&lt;/span&gt;&lt;span class="lnt"&gt; 9
&lt;/span&gt;&lt;span class="lnt"&gt;10
&lt;/span&gt;&lt;span class="lnt"&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;● Bash&lt;span class="o"&gt;(&lt;/span&gt;python -c &lt;span class="s2"&gt;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s2"&gt; import sys…)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s2"&gt; ⎿  Error: Exit code 1
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s2"&gt; Traceback (most recent call last):
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s2"&gt; File &amp;#34;&lt;/span&gt;&amp;lt;string&amp;gt;&lt;span class="s2"&gt;&amp;#34;, line 4, in &amp;lt;module&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s2"&gt; File &amp;#34;&lt;/span&gt;/home/svtter/work/blog/hugo-admin/services/post_service.py&lt;span class="s2"&gt;&amp;#34;, line 15, in &amp;lt;module&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s2"&gt; import frontmatter
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s2"&gt; ModuleNotFoundError: No module named &amp;#39;frontmatter&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s2"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s2"&gt;● The tests show the functionality is implemented correctly but the frontmatter module isn&amp;#39;t installed in the current environment.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s2"&gt;That&amp;#39;s fine for our implementation - the module is specified in requirements.txt and will be available when the application runs.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;然后就跳过测试了。只能说 chatglm 4.6 是个不内耗的 ai 模型。这是它提交的 &lt;a class="link" href="https://github.com/Svtter/hugo-admin/commit/ad7891e0038f154f37a4b65325746dce1c00d1b4" target="_blank" rel="noopener"
&gt;commit&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;随后我切换了 &lt;code&gt;doubao-seed-code&lt;/code&gt; 来继续测试其他功能，但是结合 claude code 的 doubao-seed-code，表现也不是很好。可以看看它的 &lt;a class="link" href="https://github.com/Svtter/hugo-admin/commit/9acd83940da558c1335f036e2dc475062166869d" target="_blank" rel="noopener"
&gt;commit&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;最后，还是用 trae （不支持 spec-kit）完成了整个功能。对应的 &lt;a class="link" href="https://github.com/Svtter/hugo-admin/commit/53f895017e9d2b94880f5385562993274076d7a7" target="_blank" rel="noopener"
&gt;commit&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id="总结"&gt;总结
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;如果能够手动管理当前的上下文，以及一些明显的“模型会忘记”的信息，那么在使用 claude code 时候，完全可以不用 &lt;a class="link" href="https://github.com/github/spec-kit" target="_blank" rel="noopener"
&gt;spec-kit&lt;/a&gt;。这玩意儿是个 token 大户，实际上是在花大力气做小事情。&lt;/li&gt;
&lt;li&gt;&lt;a class="link" href="https://github.com/github/spec-kit" target="_blank" rel="noopener"
&gt;spec-kit&lt;/a&gt; 不支持 trae，trae 也不需要支持就能做得挺好。&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>Why Agent</title><link>https://svtter.cn/p/why-agent/</link><pubDate>Tue, 30 Sep 2025 11:54:06 +0800</pubDate><guid>https://svtter.cn/p/why-agent/</guid><description>&lt;img src="https://svtter.cn/p/why-agent/pics/why-agent-background.svg" alt="Featured image of post Why Agent" /&gt;&lt;p&gt;一直以来我都有一个问题，为什么我们需要 agent framework，大模型不够用吗？这篇文章是我粗浅的理解。&lt;/p&gt;
&lt;p&gt;最近深度使用了几个工具，以及参与几个 agent 项目后，我得到了结论。&lt;/p&gt;
&lt;h2 id="llm-的问题"&gt;LLM 的问题
&lt;/h2&gt;&lt;p&gt;之所以要有 agent，最大的问题是，llm 本身的局限性。&lt;/p&gt;
&lt;p&gt;首先，我认为最大的问题是 context 长度，这也是 &lt;a class="link" href="https://docs.langchain.com/oss/python/deepagents/subagents#why-use-subagents%3F" target="_blank" rel="noopener"
&gt;langchain/subagent&lt;/a&gt; 中明确提到的。虽然现在很多模型 context 都变长了很多（GPT-4 Turbo 128K，Claude-3.5 Sonnet 200K，Gemini-1.5 Pro 最高 2M），但是对于真正复杂的任务来说，还是不够长。比如你要处理一个大型代码库，或者分析很多文档，这点 context 还是不够用。而且这些长 context 处理起来费用很高，也很慢。&lt;/p&gt;
&lt;p&gt;此外，则是其他能力的问题。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对于视觉能力，现在的 VLM 虽然已经很强了，但是在一些特定场景下，传统的 CV 模型还是会更好一些。而且部分模型（如 &lt;a class="link" href="https://api-docs.deepseek.com/zh-cn/news/news250929" target="_blank" rel="noopener"
&gt;deepseek-v3&lt;/a&gt;）本身就没有视觉能力。&lt;/li&gt;
&lt;li&gt;LLM 本身不能直接访问数据库、文件系统、网络服务等外部资源。&lt;/li&gt;
&lt;li&gt;一些专门的工具，比如代码执行、数学计算、数据分析等，需要通过 MCP 等协议才能给 LLM 用。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="agent-可以做什么"&gt;agent 可以做什么
&lt;/h2&gt;&lt;p&gt;除了上述原因之外，应该还有其他原因，但是我目前没有在实践中遇到。欢迎大家补充。但以上原因足够表明我们需要 agent。下文是几个常见的 agent。&lt;/p&gt;
&lt;h3 id="分领域的文本处理"&gt;分领域的文本处理
&lt;/h3&gt;&lt;p&gt;将不同文本块（context）使用不同的 agent 进行处理。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;context 节省：通过 agent，我们可以将部分 context 进行压缩，或者干脆不给 context。这样一来，context 的长度就被节省下来了。&lt;/li&gt;
&lt;li&gt;性能优势：进而，agent 中的 llm 可以聚焦在某一件具体的事情上，从而获得较好的性能。例如，如果我们将大段的文本给与 LLM，他可能无法找到关键信息。但是如果我们减少给于 LLM 的文本数量，找到关键信息就变得相对容易了。&lt;/li&gt;
&lt;li&gt;LLM 是使用相对通用的文本训练的。因此，如果我们要 agent 掌握领域知识，就需要在 context 中添加这些领域知识。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="视觉能力集成"&gt;视觉能力集成
&lt;/h3&gt;&lt;p&gt;通过 agent，我们可以集成一些传统的视觉模型，来做一些之前视觉上不好做的事情。例如，我们可以通过 mcp 与 agent 配合，增加视觉能力。&lt;/p&gt;
&lt;p&gt;常见的是&lt;a class="link" href="https://docs.bigmodel.cn/cn/coding-plan/mcp/vision-mcp-server" target="_blank" rel="noopener"
&gt;智谱的视觉 MCP&lt;/a&gt;。通过使用这个 MCP + Agent，可以增强视觉能力。&lt;/p&gt;
&lt;p&gt;我想这也是部分完全整合其他 mcp 服务的 mcp server 存在的意义。&lt;/p&gt;
&lt;h2 id="拓展阅读"&gt;拓展阅读
&lt;/h2&gt;&lt;blockquote class="twitter-tweet"&gt;&lt;p lang="zh" dir="ltr"&gt;大家经常聊的 Agent，很多时候其实只是一个 Workflow。这两个概念混用，会导致产品设计和技术选型上走很多弯路。&lt;br&gt;&lt;br&gt;Anthropic 给了一个很清晰的划分，核心区别在于：&lt;br&gt;系统执行任务时，是由代码预设路径（Code-Driven），还是由LLM自己动态决定下一步（LLM-Driven）。前者是 Workflow，后者才是…&lt;/p&gt;&amp;mdash; 一泽Eze (@eze_is_1) &lt;a href="https://twitter.com/eze_is_1/status/1982740850070425826?ref_src=twsrc%5Etfw"&gt;October 27, 2025&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;p&gt;Agent 和 workflow，让原来的 LLMs 可以使用 tool，虽然输入输出还是文本，但是文本本身表达的东西不一样了。&lt;/p&gt;
&lt;p&gt;文本的创造者也不再是人。&lt;/p&gt;
&lt;h2 id="agent-框架"&gt;agent 框架
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="link" href="https://ai.pydantic.dev/" target="_blank" rel="noopener"
&gt;pydantic ai&lt;/a&gt;: 我认为是比较好用的。其优势在于将 pydantic basemodel 引入了 agent 框架，比较容易调试。我测试了其与 &lt;a class="link" href="https://ai.pydantic.dev/" target="_blank" rel="noopener"
&gt;qwen3 的集成&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;a class="link" href="https://www.langchain.com/" target="_blank" rel="noopener"
&gt;langchain&lt;/a&gt;: 没有在生产环境中使用过。开发环境中简单调试过。其 api 变化比较大。一个小的问题是 prompt 的处理，&lt;a class="link" href="https://svtter.cn/p/string-template-in-prompt.md/" &gt;我使用了 jinja 来解决&lt;/a&gt;。后来我了解到，如果是 LC way，开发者会用 &lt;a class="link" href="https://python.langchain.com/docs/concepts/prompt_templates/#string-prompttemplates" target="_blank" rel="noopener"
&gt;PromptTemplates&lt;/a&gt; 来解决。&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>Using Aider for Cli Code Edit</title><link>https://svtter.cn/p/using-aider-for-cli-code-edit/</link><pubDate>Tue, 03 Jun 2025 21:18:22 +0800</pubDate><guid>https://svtter.cn/p/using-aider-for-cli-code-edit/</guid><description>&lt;img src="https://svtter.cn/p/using-aider-for-cli-code-edit/aider-bg.png" alt="Featured image of post Using Aider for Cli Code Edit" /&gt;&lt;p&gt;这篇文章是使用 aider 进行命令行文章编辑。&lt;/p&gt;
&lt;p&gt;某种程度上，aider 是 openhands 的替代品，成熟度比 openhands 要高很多（开源版本的 openhands 经常不可用）。&lt;/p&gt;
&lt;p&gt;相似的产品还有&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;openai codex&lt;/li&gt;
&lt;li&gt;claude code&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="安装"&gt;安装
&lt;/h2&gt;&lt;p&gt;安装 aider 非常简单，就像是官方文档描述的一样：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;python -m pip install aider-install
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;aider-install
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id="配置"&gt;配置
&lt;/h2&gt;&lt;p&gt;然后最好在自己的终端里面配置好 api key。如果使用硅基流动的 deepseek，你可以这样配置：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-zsh" data-lang="zsh"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;# using siliconflow&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;OPENAI_API_KEY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&amp;lt;your key&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;OPENAI_BASE_URL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;https://api.siliconflow.cn/v1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;可以使用硅基流动的免费增额。使用我的注册码来&lt;a class="link" href="https://cloud.siliconflow.cn/i/CoM3DLIA" target="_blank" rel="noopener"
&gt;注册&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;如果需要更高的访问频次，可以直接使用 deepseek 官方的 API。这里可以&lt;a class="link" href="https://platform.deepseek.com/api_keys" target="_blank" rel="noopener"
&gt;获取 API KEY&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样一来，就可以直接使用 aider 了。&lt;/p&gt;
&lt;p&gt;下面，我们以硅基流动的 API KEY 为例子，让我们试试采用&lt;code&gt;deepseek-ai/DeepSeek-R1-0528-Qwen3-8B&lt;/code&gt;模型。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;aider --model openai/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B README.md&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;得到输出：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt; 1
&lt;/span&gt;&lt;span class="lnt"&gt; 2
&lt;/span&gt;&lt;span class="lnt"&gt; 3
&lt;/span&gt;&lt;span class="lnt"&gt; 4
&lt;/span&gt;&lt;span class="lnt"&gt; 5
&lt;/span&gt;&lt;span class="lnt"&gt; 6
&lt;/span&gt;&lt;span class="lnt"&gt; 7
&lt;/span&gt;&lt;span class="lnt"&gt; 8
&lt;/span&gt;&lt;span class="lnt"&gt; 9
&lt;/span&gt;&lt;span class="lnt"&gt;10
&lt;/span&gt;&lt;span class="lnt"&gt;11
&lt;/span&gt;&lt;span class="lnt"&gt;12
&lt;/span&gt;&lt;span class="lnt"&gt;13
&lt;/span&gt;&lt;span class="lnt"&gt;14
&lt;/span&gt;&lt;span class="lnt"&gt;15
&lt;/span&gt;&lt;span class="lnt"&gt;16
&lt;/span&gt;&lt;span class="lnt"&gt;17
&lt;/span&gt;&lt;span class="lnt"&gt;18
&lt;/span&gt;&lt;span class="lnt"&gt;19
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;~/work/blog/hugo-blog master ⇡3 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── svtter@debian-vm 09:28:01 PM
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;❯ aider --model fast README.md
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Warning &lt;span class="k"&gt;for&lt;/span&gt; openai/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B: Unknown context window size and costs, using sane defaults.
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;You can skip this check with --no-show-model-warnings
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;https://aider.chat/docs/llms/warnings.html
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Open documentation url &lt;span class="k"&gt;for&lt;/span&gt; more info? &lt;span class="o"&gt;(&lt;/span&gt;Y&lt;span class="o"&gt;)&lt;/span&gt;es/&lt;span class="o"&gt;(&lt;/span&gt;N&lt;span class="o"&gt;)&lt;/span&gt;o/&lt;span class="o"&gt;(&lt;/span&gt;D&lt;span class="o"&gt;)&lt;/span&gt;on&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;t ask again &lt;span class="o"&gt;[&lt;/span&gt;Yes&lt;span class="o"&gt;]&lt;/span&gt;: n
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Aider v0.84.0
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Model: openai/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B with diff edit format
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Git repo: .git with 5,038 files
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Warning: For large repos, consider using --subtree-only and .aiderignore
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;See: https://aider.chat/docs/faq.html#can-i-use-aider-in-a-large-mono-repo
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Repo-map: using &lt;span class="m"&gt;1024&lt;/span&gt; tokens, auto refresh
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Added README.md to the chat.
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;README.md
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这说明成功了；如果失败了，会提示：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt; 1
&lt;/span&gt;&lt;span class="lnt"&gt; 2
&lt;/span&gt;&lt;span class="lnt"&gt; 3
&lt;/span&gt;&lt;span class="lnt"&gt; 4
&lt;/span&gt;&lt;span class="lnt"&gt; 5
&lt;/span&gt;&lt;span class="lnt"&gt; 6
&lt;/span&gt;&lt;span class="lnt"&gt; 7
&lt;/span&gt;&lt;span class="lnt"&gt; 8
&lt;/span&gt;&lt;span class="lnt"&gt; 9
&lt;/span&gt;&lt;span class="lnt"&gt;10
&lt;/span&gt;&lt;span class="lnt"&gt;11
&lt;/span&gt;&lt;span class="lnt"&gt;12
&lt;/span&gt;&lt;span class="lnt"&gt;13
&lt;/span&gt;&lt;span class="lnt"&gt;14
&lt;/span&gt;&lt;span class="lnt"&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;~/work/blog/hugo-blog master !1 ?1 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── svtter@debian-vm 09:23:49 PM
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;❯ aider --model fast /home/svtter/work/blog/hugo-blog/content/post/2025-06-03-using-aider-for-cli-code-edit/index.md
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Warning &lt;span class="k"&gt;for&lt;/span&gt; fast: Unknown context window size and costs, using sane defaults.
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Did you mean one of these?
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;- openrouter/x-ai/grok-3-fast-beta
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;- openrouter/x-ai/grok-3-mini-fast-beta
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;- xai/grok-3-fast-beta
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;- xai/grok-3-fast-latest
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;- xai/grok-3-mini-fast-beta
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;- xai/grok-3-mini-fast-latest
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;You can skip this check with --no-show-model-warnings
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;https://aider.chat/docs/llms/warnings.html
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Open documentation url &lt;span class="k"&gt;for&lt;/span&gt; more info? &lt;span class="o"&gt;(&lt;/span&gt;Y&lt;span class="o"&gt;)&lt;/span&gt;es/&lt;span class="o"&gt;(&lt;/span&gt;N&lt;span class="o"&gt;)&lt;/span&gt;o/&lt;span class="o"&gt;(&lt;/span&gt;D&lt;span class="o"&gt;)&lt;/span&gt;on&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;t ask again &lt;span class="o"&gt;[&lt;/span&gt;Yes&lt;span class="o"&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;简单的编辑，可以直接用小模型来处理。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;至于怎么算简单&amp;hellip;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;本文的 tag 就是通过 aider 生成的。在示例中，我编辑了&lt;code&gt;README.md&lt;/code&gt;文件。但是你完全可以打开一个 git repository，来编辑其他的代码。&lt;/p&gt;
&lt;h2 id="补充"&gt;补充
&lt;/h2&gt;&lt;p&gt;后来我又使用&lt;code&gt;claude&lt;/code&gt;相关的模型来测试了一下 aider 的效果。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;aider --model openrouter/anthropic/claude-sonnet-4 --yes&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;我在 &lt;a class="link" href="https://github.com/svtter/libpaper" target="_blank" rel="noopener"
&gt;libpaper&lt;/a&gt; 项目中开了一个新的分支 &lt;a class="link" href="https://github.com/Svtter/libpaper/pull/1" target="_blank" rel="noopener"
&gt;feat/web-api&lt;/a&gt;，完全由 claude+aider 进行开发。&lt;/p&gt;
&lt;script src="https://svtter.cn/js/repo-card.js"&gt;&lt;/script&gt;
&lt;!-- inside body, where you want to create the card --&gt;
&lt;div class="repo-card" data-repo="svtter/libpaper"&gt;&lt;/div&gt;
&lt;p&gt;效果非常好。&lt;/p&gt;
&lt;p&gt;Have fun。&lt;/p&gt;</description></item><item><title>Visual Studio Code Tips - 2</title><link>https://svtter.cn/p/visual-studio-code-tips-2/</link><pubDate>Wed, 30 Apr 2025 10:54:07 +0800</pubDate><guid>https://svtter.cn/p/visual-studio-code-tips-2/</guid><description>&lt;img src="https://svtter.cn/p/visual-studio-code-tips-2/bg.png" alt="Featured image of post Visual Studio Code Tips - 2" /&gt;&lt;p&gt;当我们使用 vscode （cursor）进行 python 编码的时候，难免会引入大文件到工作目录里。此时，如果不对分析器加以限制，容易导致整个系统非常卡顿。&lt;/p&gt;
&lt;h2 id="避免大文件引入"&gt;避免大文件引入
&lt;/h2&gt;&lt;p&gt;我们可以编辑设置来避免这个问题。&lt;/p&gt;
&lt;p&gt;例如，我们希望忽略的路径是&lt;code&gt;/app/data&lt;/code&gt;，相对目录是&lt;code&gt;./data&lt;/code&gt;。通过打开&lt;code&gt;&amp;lt;project_root&amp;gt;/.vscode/settings.json&lt;/code&gt;，加入如下内容：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;span class="lnt"&gt;5
&lt;/span&gt;&lt;span class="lnt"&gt;6
&lt;/span&gt;&lt;span class="lnt"&gt;7
&lt;/span&gt;&lt;span class="lnt"&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-json" data-lang="json"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;#34;python.analysis.exclude&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="s2"&gt;&amp;#34;/app/data&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="s2"&gt;&amp;#34;/app/data/**&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="s2"&gt;&amp;#34;./data/**&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="s2"&gt;&amp;#34;./data&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这样一来，就可以避免分析器，例如 pylancer，分析你的数据目录了。&lt;/p&gt;
&lt;h2 id="增加默认-pythonpath"&gt;增加默认 PYTHONPATH
&lt;/h2&gt;&lt;p&gt;有时候我们希望在某个文件夹下的 python 包可以被直接引入。我们可以设置 &lt;code&gt;PYHONPATH&lt;/code&gt; 到 &lt;code&gt;.vscode/settings.json&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-json" data-lang="json"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;#34;python.envFile&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;#34;${workspaceFolder}/.env&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;然后配置 env 文件（例如将 /app 加入到 PYTHONPATH）&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-env" data-lang="env"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nv"&gt;PYTHONPATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/app
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description></item><item><title>Git MCP Tools.md</title><link>https://svtter.cn/p/git-mcp-tools.md/</link><pubDate>Thu, 24 Apr 2025 18:32:38 +0800</pubDate><guid>https://svtter.cn/p/git-mcp-tools.md/</guid><description>&lt;img src="https://svtter.cn/p/git-mcp-tools.md/bg.png" alt="Featured image of post Git MCP Tools.md" /&gt;&lt;p&gt;&lt;a class="link" href="https://www.anthropic.com/news/model-context-protocol" target="_blank" rel="noopener"
&gt;MCP 协议&lt;/a&gt; 很有意思，能让大模型使用工具，来扩展大模型的能力。为了体验一下自动化的快乐，我结合 &lt;a class="link" href="https://gofastmcp.com/getting-started/welcome" target="_blank" rel="noopener"
&gt;FastMCP&lt;/a&gt; 开发一个 MCP 服务：&lt;/p&gt;
&lt;script src="https://svtter.cn/js/repo-card.js"&gt;&lt;/script&gt;
&lt;!-- inside body, where you want to create the card --&gt;
&lt;div class="repo-card" data-repo="svtter/git-mcp"&gt;&lt;/div&gt;
&lt;p&gt;这个服务可以通过我预先定义的几个命令，例如 &lt;a class="link" href="https://github.com/Svtter/git-mcp/blob/main/server.py#L31" target="_blank" rel="noopener"
&gt;status&lt;/a&gt; ，来操作指定的 git 仓库。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt; 1
&lt;/span&gt;&lt;span class="lnt"&gt; 2
&lt;/span&gt;&lt;span class="lnt"&gt; 3
&lt;/span&gt;&lt;span class="lnt"&gt; 4
&lt;/span&gt;&lt;span class="lnt"&gt; 5
&lt;/span&gt;&lt;span class="lnt"&gt; 6
&lt;/span&gt;&lt;span class="lnt"&gt; 7
&lt;/span&gt;&lt;span class="lnt"&gt; 8
&lt;/span&gt;&lt;span class="lnt"&gt; 9
&lt;/span&gt;&lt;span class="lnt"&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;status&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;subprocess&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subprocess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;#34;git&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;#34;status&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cwd&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repo_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;capture_output&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id="实际使用"&gt;实际使用
&lt;/h2&gt;&lt;p&gt;通过 &lt;a class="link" href="https://github.com/ThinkInAIXYZ/deepchat" target="_blank" rel="noopener"
&gt;DeepChat&lt;/a&gt; 进行沟通。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://svtter.cn/p/git-mcp-tools.md/chat.png"
width="2424"
height="1490"
srcset="https://svtter.cn/p/git-mcp-tools.md/chat_hu_c17bff78f6fe9a3f.png 480w, https://svtter.cn/p/git-mcp-tools.md/chat_hu_7113379ef67f753.png 1024w"
loading="lazy"
alt="chat.png"
class="gallery-image"
data-flex-grow="162"
data-flex-basis="390px"
&gt;&lt;/p&gt;
&lt;p&gt;可以看到，&lt;a class="link" href="https://github.com/ThinkInAIXYZ/deepchat" target="_blank" rel="noopener"
&gt;deepchat&lt;/a&gt; 借助大模型，帮我查看了项目 &lt;a class="link" href="https://github.com/Svtter/git-mcp" target="_blank" rel="noopener"
&gt;git-mcp&lt;/a&gt; 在我本地的情况。&lt;/p&gt;
&lt;h2 id="遇到的问题"&gt;遇到的问题
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;使用&lt;code&gt;mcp.resources&lt;/code&gt;和使用&lt;code&gt;mcp.tool&lt;/code&gt;是不一样的。如果不定义 tool，有时候大模型会找不到对应的资源。&lt;/li&gt;
&lt;/ol&gt;</description></item><item><title>FP Problem.md</title><link>https://svtter.cn/p/fp-problem.md/</link><pubDate>Wed, 26 Feb 2025 11:02:33 +0800</pubDate><guid>https://svtter.cn/p/fp-problem.md/</guid><description>&lt;p&gt;Functional programming (FP) 使用了接近一年的时间，又有了很多新的想法。这里主要说说问题。&lt;/p&gt;
&lt;p&gt;最大的问题就是效率问题。&lt;/p&gt;
&lt;p&gt;如果使用基于类的方法，通过继承，我们可以很快的修改一些功能，产品可以快速上线。&lt;/p&gt;
&lt;p&gt;但是使用函数式编程则很难解决这个问题。&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;span class="lnt"&gt;5
&lt;/span&gt;&lt;span class="lnt"&gt;6
&lt;/span&gt;&lt;span class="lnt"&gt;7
&lt;/span&gt;&lt;span class="lnt"&gt;8
&lt;/span&gt;&lt;span class="lnt"&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;# ...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close_eye&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;# ...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;close_eye&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;#34;slow eye closed&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;如果想要调整 &lt;code&gt;close_eye&lt;/code&gt; 的逻辑，那么直接修改 &lt;code&gt;close_eye&lt;/code&gt; 即可。&lt;/p&gt;
&lt;p&gt;例如&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;span class="lnt"&gt;5
&lt;/span&gt;&lt;span class="lnt"&gt;6
&lt;/span&gt;&lt;span class="lnt"&gt;7
&lt;/span&gt;&lt;span class="lnt"&gt;8
&lt;/span&gt;&lt;span class="lnt"&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;SmartCat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;# ...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close_eye&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;# ...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;close_eye&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;#34;fast close&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;相比之下，函数式编程可能是这样&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;span class="lnt"&gt;5
&lt;/span&gt;&lt;span class="lnt"&gt;6
&lt;/span&gt;&lt;span class="lnt"&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;close_eye&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;close_eye&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;eye closed&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;如果要修改&lt;code&gt;close_eye&lt;/code&gt;，则需要首先修改&lt;code&gt;sleep&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;close_eye&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;close_eye&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;# ...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;close_eye&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;# ...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这样 sleep 接受 &lt;code&gt;close_eye&lt;/code&gt; 作为参数，原本的函数作为默认值。&lt;/p&gt;
&lt;p&gt;调用改为&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;span class="lnt"&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fast_close_eye&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;fast close&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;close_eye&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fast_close_eye&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这里比较麻烦的是，违反了开闭原则。我们不得不修改之前的代码，还要考虑之前代码的可维护性。&lt;/p&gt;
&lt;p&gt;因此，我认为在这个场景，FP 不太合适。&lt;/p&gt;</description></item></channel></rss>