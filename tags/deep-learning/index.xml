<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning on Svtter&#39;s Blog</title>
    <link>https://svtter.cn/tags/deep-learning/</link>
    <description>Recent content in Deep Learning on Svtter&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 24 Feb 2025 22:01:57 +0800</lastBuildDate>
    <atom:link href="https://svtter.cn/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Dataset 和 DataLoader 的区别是什么</title>
      <link>https://svtter.cn/post/2025-02-24-different-between-dataset-and-dataloader.md/</link>
      <pubDate>Mon, 24 Feb 2025 22:01:57 +0800</pubDate>
      <guid>https://svtter.cn/post/2025-02-24-different-between-dataset-and-dataloader.md/</guid>
      <description>&lt;p&gt;在 &lt;code&gt;torch.utils.data&lt;/code&gt; 中，有两个类，一个是&lt;code&gt;Dataset&lt;/code&gt;，另一个是&lt;code&gt;DataLoader&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;这两个类的主要区别是什么？&lt;/p&gt;</description>
    </item>
    <item>
      <title>Where to Put Your Data Folder.md</title>
      <link>https://svtter.cn/post/2025-02-24-where-to-put-your-data-folder.md/</link>
      <pubDate>Mon, 24 Feb 2025 14:34:56 +0800</pubDate>
      <guid>https://svtter.cn/post/2025-02-24-where-to-put-your-data-folder.md/</guid>
      <description>&lt;p&gt;在训练模型时，我们应该尽可能的把数据和代码放在同一个位置。&lt;/p&gt;</description>
    </item>
    <item>
      <title>图片数据集的浏览</title>
      <link>https://svtter.cn/post/2025-02-05-better-dataset-viewer.md/</link>
      <pubDate>Sun, 12 Jan 2025 18:31:12 +0800</pubDate>
      <guid>https://svtter.cn/post/2025-02-05-better-dataset-viewer.md/</guid>
      <description>&lt;p&gt;数据集浏览是个比较麻烦的事情。尤其是数据集比较大的时候。&lt;/p&gt;</description>
    </item>
    <item>
      <title>My Keras tricks</title>
      <link>https://svtter.cn/2019/01/07/my-keras-tricks/</link>
      <pubDate>Mon, 07 Jan 2019 01:00:00 +0800</pubDate>
      <guid>https://svtter.cn/2019/01/07/my-keras-tricks/</guid>
      <description>&lt;p&gt;记录了一些使用 keras 的技巧。&lt;/p&gt;</description>
    </item>
    <item>
      <title>我应该学哪个深度学习框架？</title>
      <link>https://svtter.cn/2019/01/02/%E6%88%91%E5%BA%94%E8%AF%A5%E5%AD%A6%E5%93%AA%E4%B8%AA%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%EF%BC%9F/</link>
      <pubDate>Wed, 02 Jan 2019 01:00:00 +0800</pubDate>
      <guid>https://svtter.cn/2019/01/02/%E6%88%91%E5%BA%94%E8%AF%A5%E5%AD%A6%E5%93%AA%E4%B8%AA%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%EF%BC%9F/</guid>
      <description>&lt;img src=&#34;https://i0.wp.com/ws1.sinaimg.cn/large/c53b1907ly1fysk81yoinj21wa0zgael.jpg?w=625&amp;#038;ssl=1&#34; data-recalc-dims=&#34;1&#34; /&gt;&#xA;&lt;p&gt;答案似乎显然意见 😉&lt;/p&gt;</description>
    </item>
    <item>
      <title>beam search – 一个搜索策略</title>
      <link>https://svtter.cn/2018/11/23/beam-search-%E4%B8%80%E4%B8%AA%E6%90%9C%E7%B4%A2%E7%AD%96%E7%95%A5/</link>
      <pubDate>Fri, 23 Nov 2018 01:00:00 +0800</pubDate>
      <guid>https://svtter.cn/2018/11/23/beam-search-%E4%B8%80%E4%B8%AA%E6%90%9C%E7%B4%A2%E7%AD%96%E7%95%A5/</guid>
      <description>&lt;p&gt;这篇文章不建议读，2018年写的，不知所云。&lt;/p&gt;&#xA;&lt;p&gt;beam search 是一个近似搜索策略，用于在候选可能中选择最好的结果。&lt;a href=&#34;https://hackernoon.com/beam-search-a-search-strategy-5d92fb7817f&#34;&gt;原文链接&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>对于 CTC 的一个直观理解与解释</title>
      <link>https://svtter.cn/2018/11/22/%E5%AF%B9%E4%BA%8E-ctc-%E7%9A%84%E4%B8%80%E4%B8%AA%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3%E4%B8%8E%E8%A7%A3%E9%87%8A/</link>
      <pubDate>Thu, 22 Nov 2018 01:00:00 +0800</pubDate>
      <guid>https://svtter.cn/2018/11/22/%E5%AF%B9%E4%BA%8E-ctc-%E7%9A%84%E4%B8%80%E4%B8%AA%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3%E4%B8%8E%E8%A7%A3%E9%87%8A/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;这篇文章是一个翻译：&lt;a href=&#34;https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c&#34;&gt;towardsdatascience-ctc&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;通过 CTC loss 以及编码操作进行文字识别。&lt;/p&gt;</description>
    </item>
    <item>
      <title>使用主动学习加速机器学习</title>
      <link>https://svtter.cn/2018/11/20/%E4%BD%BF%E7%94%A8%E4%B8%BB%E5%8A%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Tue, 20 Nov 2018 01:00:00 +0800</pubDate>
      <guid>https://svtter.cn/2018/11/20/%E4%BD%BF%E7%94%A8%E4%B8%BB%E5%8A%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</guid>
      <description>&lt;blockquote class=&#34;wp-block-quote&#34;&gt;&#xA;  &lt;p&gt;&#xA;    一篇 medium 文章的渣翻&#xA;  &lt;/p&gt;&#xA;&lt;p&gt;&lt;cite&gt;&lt;a href=&#34;https://becominghuman.ai/accelerate-machine-learning-with-active-learning-96cea4b72fdb&#34;&gt;https://becominghuman.ai/accelerate-machine-learning-with-active-learning-96cea4b72fdb&lt;/a&gt;&lt;/cite&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;让我们讨论一下主动学习。我相信这个方法可以极大的增速，以及减少许多机器学习工程的花费。这篇文章我将从两个部分说明这个问题。在第一部分，我给出了一个极高的层级的主动学习的说明，以及如何把它利用到机器学习工程中。在第二部分，深入到一个主动学习 demo 中。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Keras坑</title>
      <link>https://svtter.cn/2018/02/01/keras%E5%9D%91/</link>
      <pubDate>Thu, 01 Feb 2018 01:00:00 +0800</pubDate>
      <guid>https://svtter.cn/2018/02/01/keras%E5%9D%91/</guid>
      <description>&lt;p&gt;使用Keras做分类的时候踩了一个坑，也是拿来主义的锅，估计也有不少同志遇到。&lt;/p&gt;&#xA;&lt;p&gt;在进行分类的时候，往往使用&lt;code&gt;categorical_crossentropy&lt;/code&gt;，有时候萌新（像我）会用&lt;code&gt;binary_crossentropy&lt;/code&gt;，虽然结果可能上浮30%，但是这个结果是不对的。&lt;code&gt;model.fit&lt;/code&gt;以及&lt;code&gt;model.evaluate&lt;/code&gt;给出的&lt;code&gt;acc&lt;/code&gt;的值都是有问题的，正确的计算方法应该是：&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
