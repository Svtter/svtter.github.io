<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ai on Svtter's Blog</title><link>https://svtter.cn/tags/ai/</link><description>Recent content in Ai on Svtter's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Fri, 24 Oct 2025 17:03:48 +0800</lastBuildDate><atom:link href="https://svtter.cn/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>我又买了 Kimi Coding Plan</title><link>https://svtter.cn/p/%E6%88%91%E5%8F%88%E4%B9%B0%E4%BA%86-kimi-coding-plan/</link><pubDate>Fri, 24 Oct 2025 17:03:48 +0800</pubDate><guid>https://svtter.cn/p/%E6%88%91%E5%8F%88%E4%B9%B0%E4%BA%86-kimi-coding-plan/</guid><description>&lt;blockquote class="twitter-tweet"&gt;&lt;p lang="en" dir="ltr"&gt;😋, it&amp;#39;s coming. &lt;a href="https://twitter.com/Kimi_Moonshot?ref_src=twsrc%5Etfw"&gt;@Kimi_Moonshot&lt;/a&gt; now has a subscription-based plan now!&lt;br&gt;&lt;br&gt;Start from $7/month up to $28.5/month, about 1/7 compared to Claude Code 😋 &lt;a href="https://t.co/hTnIbVjebg"&gt;https://t.co/hTnIbVjebg&lt;/a&gt; &lt;a href="https://t.co/Mi3EjOl346"&gt;pic.twitter.com/Mi3EjOl346&lt;/a&gt;&lt;/p&gt;&amp;mdash; Xuanwo (@OnlyXuanwo) &lt;a href="https://twitter.com/OnlyXuanwo/status/1981586444658548736?ref_src=twsrc%5Etfw"&gt;October 24, 2025&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;p&gt;感触：kimi 集成 claude code 相比于 glm 要好很多。例如，不需要单独配置 web search。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-fallback" data-lang="fallback"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&amp;gt; 尝试搜索一下 svtter
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;● Web Search(&amp;#34;svtter&amp;#34;)
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; ⎿  Did 1 search in 19s
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在配置好 kimi 之后，即可使用。&lt;/p&gt;
&lt;p&gt;此外，在封闭测试中，kimi k2 的性能得到了&lt;a class="link" href="https://mp.weixin.qq.com/s/nil-kRM2Ef1tV3CQ-6t7Ag" target="_blank" rel="noopener"
&gt;Vercel CEO的认可&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id="cli"&gt;CLI
&lt;/h2&gt;&lt;p&gt;kimi 也有自己的 cli，具体可以看&lt;a class="link" href="https://mp.weixin.qq.com/s/M9m7vZoG8uEtGpKddAA4ZA" target="_blank" rel="noopener"
&gt;这里&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;a class="link" href="https://www.kimi.com/coding/docs/kimi-cli.html" target="_blank" rel="noopener"
&gt;官方文档&lt;/a&gt;中讲了如何购买以及使用。不过从习惯上讲我更喜欢使用 claude code。&lt;/p&gt;
&lt;h2 id="额外知识"&gt;额外知识
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;不同 kimi k2 的提供商，&lt;a class="link" href="https://mp.weixin.qq.com/s/v_r42j9YuXY7zYff6z4eXw" target="_blank" rel="noopener"
&gt;性能是不一样的&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;如果希望修改 claude code 的 provider，可以通过 &lt;a class="link" href="https://github.com/farion1231/cc-switch" target="_blank" rel="noopener"
&gt;cc-switch 项目&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="顾虑"&gt;顾虑
&lt;/h2&gt;&lt;p&gt;现在模型是 kimi-for-coding，我们无法确定这个模型是哪一个级别的模型。如果是个笨蛋模型，那我们采购的意义就很小了。现在效率为王。&lt;/p&gt;</description></item><item><title>Using Aider for Cli Code Edit</title><link>https://svtter.cn/p/using-aider-for-cli-code-edit/</link><pubDate>Tue, 03 Jun 2025 21:18:22 +0800</pubDate><guid>https://svtter.cn/p/using-aider-for-cli-code-edit/</guid><description>&lt;img src="https://svtter.cn/p/using-aider-for-cli-code-edit/aider-bg.png" alt="Featured image of post Using Aider for Cli Code Edit" /&gt;&lt;p&gt;这篇文章是使用 aider 进行命令行文章编辑。&lt;/p&gt;
&lt;p&gt;某种程度上，aider 是 openhands 的替代品，成熟度比 openhands 要高很多（开源版本的 openhands 经常不可用）。&lt;/p&gt;
&lt;p&gt;相似的产品还有&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;openai codex&lt;/li&gt;
&lt;li&gt;claude code&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="安装"&gt;安装
&lt;/h2&gt;&lt;p&gt;安装 aider 非常简单，就像是官方文档描述的一样：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;python -m pip install aider-install
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;aider-install
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id="配置"&gt;配置
&lt;/h2&gt;&lt;p&gt;然后最好在自己的终端里面配置好 api key。如果使用硅基流动的 deepseek，你可以这样配置：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-zsh" data-lang="zsh"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;# using siliconflow&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;OPENAI_API_KEY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&amp;lt;your key&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;OPENAI_BASE_URL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;https://api.siliconflow.cn/v1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;可以使用硅基流动的免费增额。使用我的注册码来&lt;a class="link" href="https://cloud.siliconflow.cn/i/CoM3DLIA" target="_blank" rel="noopener"
&gt;注册&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;如果需要更高的访问频次，可以直接使用 deepseek 官方的 API。这里可以&lt;a class="link" href="https://platform.deepseek.com/api_keys" target="_blank" rel="noopener"
&gt;获取 API KEY&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样一来，就可以直接使用 aider 了。&lt;/p&gt;
&lt;p&gt;下面，我们以硅基流动的 API KEY 为例子，让我们试试采用&lt;code&gt;deepseek-ai/DeepSeek-R1-0528-Qwen3-8B&lt;/code&gt;模型。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;aider --model openai/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B README.md&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;得到输出：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt; 1
&lt;/span&gt;&lt;span class="lnt"&gt; 2
&lt;/span&gt;&lt;span class="lnt"&gt; 3
&lt;/span&gt;&lt;span class="lnt"&gt; 4
&lt;/span&gt;&lt;span class="lnt"&gt; 5
&lt;/span&gt;&lt;span class="lnt"&gt; 6
&lt;/span&gt;&lt;span class="lnt"&gt; 7
&lt;/span&gt;&lt;span class="lnt"&gt; 8
&lt;/span&gt;&lt;span class="lnt"&gt; 9
&lt;/span&gt;&lt;span class="lnt"&gt;10
&lt;/span&gt;&lt;span class="lnt"&gt;11
&lt;/span&gt;&lt;span class="lnt"&gt;12
&lt;/span&gt;&lt;span class="lnt"&gt;13
&lt;/span&gt;&lt;span class="lnt"&gt;14
&lt;/span&gt;&lt;span class="lnt"&gt;15
&lt;/span&gt;&lt;span class="lnt"&gt;16
&lt;/span&gt;&lt;span class="lnt"&gt;17
&lt;/span&gt;&lt;span class="lnt"&gt;18
&lt;/span&gt;&lt;span class="lnt"&gt;19
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;~/work/blog/hugo-blog master ⇡3 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── svtter@debian-vm 09:28:01 PM
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;❯ aider --model fast README.md
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Warning &lt;span class="k"&gt;for&lt;/span&gt; openai/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B: Unknown context window size and costs, using sane defaults.
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;You can skip this check with --no-show-model-warnings
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;https://aider.chat/docs/llms/warnings.html
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Open documentation url &lt;span class="k"&gt;for&lt;/span&gt; more info? &lt;span class="o"&gt;(&lt;/span&gt;Y&lt;span class="o"&gt;)&lt;/span&gt;es/&lt;span class="o"&gt;(&lt;/span&gt;N&lt;span class="o"&gt;)&lt;/span&gt;o/&lt;span class="o"&gt;(&lt;/span&gt;D&lt;span class="o"&gt;)&lt;/span&gt;on&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;t ask again &lt;span class="o"&gt;[&lt;/span&gt;Yes&lt;span class="o"&gt;]&lt;/span&gt;: n
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Aider v0.84.0
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Model: openai/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B with diff edit format
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Git repo: .git with 5,038 files
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Warning: For large repos, consider using --subtree-only and .aiderignore
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;See: https://aider.chat/docs/faq.html#can-i-use-aider-in-a-large-mono-repo
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Repo-map: using &lt;span class="m"&gt;1024&lt;/span&gt; tokens, auto refresh
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Added README.md to the chat.
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;README.md
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这说明成功了；如果失败了，会提示：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt; 1
&lt;/span&gt;&lt;span class="lnt"&gt; 2
&lt;/span&gt;&lt;span class="lnt"&gt; 3
&lt;/span&gt;&lt;span class="lnt"&gt; 4
&lt;/span&gt;&lt;span class="lnt"&gt; 5
&lt;/span&gt;&lt;span class="lnt"&gt; 6
&lt;/span&gt;&lt;span class="lnt"&gt; 7
&lt;/span&gt;&lt;span class="lnt"&gt; 8
&lt;/span&gt;&lt;span class="lnt"&gt; 9
&lt;/span&gt;&lt;span class="lnt"&gt;10
&lt;/span&gt;&lt;span class="lnt"&gt;11
&lt;/span&gt;&lt;span class="lnt"&gt;12
&lt;/span&gt;&lt;span class="lnt"&gt;13
&lt;/span&gt;&lt;span class="lnt"&gt;14
&lt;/span&gt;&lt;span class="lnt"&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;~/work/blog/hugo-blog master !1 ?1 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── svtter@debian-vm 09:23:49 PM
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;❯ aider --model fast /home/svtter/work/blog/hugo-blog/content/post/2025-06-03-using-aider-for-cli-code-edit/index.md
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Warning &lt;span class="k"&gt;for&lt;/span&gt; fast: Unknown context window size and costs, using sane defaults.
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Did you mean one of these?
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;- openrouter/x-ai/grok-3-fast-beta
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;- openrouter/x-ai/grok-3-mini-fast-beta
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;- xai/grok-3-fast-beta
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;- xai/grok-3-fast-latest
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;- xai/grok-3-mini-fast-beta
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;- xai/grok-3-mini-fast-latest
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;You can skip this check with --no-show-model-warnings
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;https://aider.chat/docs/llms/warnings.html
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Open documentation url &lt;span class="k"&gt;for&lt;/span&gt; more info? &lt;span class="o"&gt;(&lt;/span&gt;Y&lt;span class="o"&gt;)&lt;/span&gt;es/&lt;span class="o"&gt;(&lt;/span&gt;N&lt;span class="o"&gt;)&lt;/span&gt;o/&lt;span class="o"&gt;(&lt;/span&gt;D&lt;span class="o"&gt;)&lt;/span&gt;on&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;t ask again &lt;span class="o"&gt;[&lt;/span&gt;Yes&lt;span class="o"&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;简单的编辑，可以直接用小模型来处理。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;至于怎么算简单&amp;hellip;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文的 tag 就是通过 aider 生成的。在示例中，我编辑了&lt;code&gt;README.md&lt;/code&gt;文件。但是你完全可以打开一个 git repository，来编辑其他的代码。&lt;/p&gt;
&lt;h2 id="补充"&gt;补充
&lt;/h2&gt;&lt;p&gt;后来我又使用&lt;code&gt;claude&lt;/code&gt;相关的模型来测试了一下 aider 的效果。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;aider --model openrouter/anthropic/claude-sonnet-4 --yes&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;我在 &lt;a class="link" href="https://github.com/svtter/libpaper" target="_blank" rel="noopener"
&gt;libpaper&lt;/a&gt; 项目中开了一个新的分支 &lt;a class="link" href="https://github.com/Svtter/libpaper/pull/1" target="_blank" rel="noopener"
&gt;feat/web-api&lt;/a&gt;，完全由 claude+aider 进行开发。&lt;/p&gt;
&lt;script src="https://tarptaeya.github.io/repo-card/repo-card.js"&gt;&lt;/script&gt;
&lt;!-- inside body, where you want to create the card --&gt;
&lt;div class="repo-card" data-repo="svtter/libpaper"&gt;&lt;/div&gt;
&lt;p&gt;效果非常好。&lt;/p&gt;
&lt;p&gt;Have fun。&lt;/p&gt;</description></item><item><title>Why I Still Write Blog Post About Coding.md</title><link>https://svtter.cn/p/why-i-still-write-blog-post-about-coding.md/</link><pubDate>Mon, 24 Feb 2025 22:12:12 +0800</pubDate><guid>https://svtter.cn/p/why-i-still-write-blog-post-about-coding.md/</guid><description>&lt;img src="https://svtter.cn/p/why-i-still-write-blog-post-about-coding.md/background.webp" alt="Featured image of post Why I Still Write Blog Post About Coding.md" /&gt;&lt;p&gt;这几天几个我关注的高质量公众号都停更了他们原来的内容，转向了 AI。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class="link" href="https://mp.weixin.qq.com/s/9VtjDwbxu1BxLTbgHVQeXA" target="_blank" rel="noopener"
&gt;Farewell Go，Hello AI：是时候说再见了&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;或者干脆停更了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class="link" href="https://mp.weixin.qq.com/s/XHOWSVhTHWSY9VjM9ioLcA" target="_blank" rel="noopener"
&gt;我不再更新 Python 了。。。。&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我的博客仍然会更新编程相关的文章。&lt;/p&gt;
&lt;p&gt;目前 AI 还没有达到让我完完全全不用动脑的程度。大多数情况下，我还是使用它的自动补全，而不是 compose with agent。
因为生成的质量一般般。
AI 还不能很好的理解大段的文字，以及背后的含义。我认为现在的 LLMs 就是一个相对性能较强的多任务 NLP 解析器。&lt;/p&gt;
&lt;p&gt;当然，尽管只是一个多任务 NLP 解析器，其能力已经可以做成大量的事情了。如果把他的性能升级考虑进去，那么确实会有更多的想象力。&lt;/p&gt;
&lt;p&gt;不过目前为止（2025年02月24日），做事情效率更好的方式，还是把知识 cache 到我的脑子。&lt;/p&gt;
&lt;p&gt;LLMs 是一个新的索引器，他可以将之前存储在互联网和磁盘上的知识快速检索出来供我使用。&lt;/p&gt;
&lt;p&gt;但是我自己大脑中的知识图谱，是初步告诉我应该检索什么，如何提问，以及整理需求的第一线。&lt;/p&gt;
&lt;p&gt;因此，如果我是一个数字人，那么 coding post 是我更新大脑中 cache 以及知识图谱的过程。&lt;/p&gt;
&lt;p&gt;最后，我认为几个老技术关注 AI 多一点也没什么问题。AI 正在创造更大的价值，Coding Skill 尽管仍有效果，但是贬值已经是不可否认的事实了。&lt;/p&gt;
&lt;!-- 关于 AI，我认为还有几个问题值得思考：
1. 知识库的数据结构是什么? --&gt;
&lt;!-- 2. 跟着 Dify 走，我们可以做很多新的事情。 --&gt;</description></item><item><title>如何应对 AI 编程助手带来的技术革新？</title><link>https://svtter.cn/p/%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9-ai-%E7%BC%96%E7%A8%8B%E5%8A%A9%E6%89%8B%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%8A%80%E6%9C%AF%E9%9D%A9%E6%96%B0/</link><pubDate>Tue, 10 Sep 2024 20:33:05 +0800</pubDate><guid>https://svtter.cn/p/%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9-ai-%E7%BC%96%E7%A8%8B%E5%8A%A9%E6%89%8B%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%8A%80%E6%9C%AF%E9%9D%A9%E6%96%B0/</guid><description>&lt;p&gt;AI 编程助手已经越来越强大了。近期我也使用了 &lt;a class="link" href="https://www.cursor.com/" target="_blank" rel="noopener"
&gt;cursor&lt;/a&gt;，体验非常好。我也为了 cursor 充值了一波。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://svtter.cn/p/%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9-ai-%E7%BC%96%E7%A8%8B%E5%8A%A9%E6%89%8B%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%8A%80%E6%9C%AF%E9%9D%A9%E6%96%B0/pics/buy-cursor.png"
width="2774"
height="754"
srcset="https://svtter.cn/p/%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9-ai-%E7%BC%96%E7%A8%8B%E5%8A%A9%E6%89%8B%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%8A%80%E6%9C%AF%E9%9D%A9%E6%96%B0/pics/buy-cursor_hu_3559878c871635e9.png 480w, https://svtter.cn/p/%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9-ai-%E7%BC%96%E7%A8%8B%E5%8A%A9%E6%89%8B%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%8A%80%E6%9C%AF%E9%9D%A9%E6%96%B0/pics/buy-cursor_hu_439b54427a675652.png 1024w"
loading="lazy"
alt="bug-cursor"
class="gallery-image"
data-flex-grow="367"
data-flex-basis="882px"
&gt;&lt;/p&gt;
&lt;p&gt;我想与 AI 协同工作，这是未来的趋势。同时也意味着，ai 会替代很多工程师的工作。这个不可避免的未来，实际上这要求我们工程师要具备更强的表达能力，能够让ai模型理解我们要做什么。&lt;/p&gt;
&lt;h2 id="作为可能被替代的工程师我们应该怎么办"&gt;作为可能被替代的工程师，我们应该怎么办？
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;使用 AI 技术，而不是抗拒它。你不可能让你的竞争对手不使用 ai 技术。&lt;/li&gt;
&lt;li&gt;将 AI 技术找到最适合自己的 AI 技术。就像是我们在某天下午找到一个自己最适应的 IDE 一样。然后，就像是挑选供应商一样，选择自己的 AI 技术供应商。性能最高的不一定是最好的。OpenAI 不是唯一的选择，claude 也不是。&lt;/li&gt;
&lt;li&gt;AI 是一种基础资源。就像水电，以及现在的互联网。这个观点来自&lt;a class="link" href="https://www.gsb.stanford.edu/insights/andrew-ng-why-ai-new-electricity" target="_blank" rel="noopener"
&gt;Andrew Ng: Why AI Is the New Electricity&lt;/a&gt;。生活支出中，需要为此支付一部分费用。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当我们能够较好的使用多种 AI 技术的时候，AI 对我们的威胁就不存在了。目前 AI 技术的发展来看，本质上还是人与人之间的竞争。
我们已经掌控了 AI Editor，让他们为我们所用。那么我们就可以更高效的编程，或者节省下来宝贵的时间，可以留给我们的家人。&lt;/p&gt;
&lt;h2 id="未来呢"&gt;未来呢？
&lt;/h2&gt;&lt;p&gt;我们应该多关注那些 AI 无法完成的工作，例如数学和更加复杂的逻辑。现在 AI 对于复杂逻辑的思考能力是不及人类的，对于多方面的复杂信息处理能力较弱。&lt;/p&gt;
&lt;p&gt;如果更好的 AI 出现了怎么办？
我想共产主义是一个好的途径（🤣）。实际上，共产主义追求的不是平均财富，而是人们能够在生产力极其庞大的情况下，做自己想做的事情，也能满足自己的物质和精神需要。&lt;/p&gt;</description></item></channel></rss>