<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Deepseek on Svtter's Blog</title><link>https://svtter.cn/tags/deepseek/</link><description>Recent content in Deepseek on Svtter's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sun, 02 Nov 2025 15:26:10 +0800</lastBuildDate><atom:link href="https://svtter.cn/tags/deepseek/index.xml" rel="self" type="application/rss+xml"/><item><title>一个划算的 kilocode 使用方法</title><link>https://svtter.cn/p/%E4%B8%80%E4%B8%AA%E5%88%92%E7%AE%97%E7%9A%84-kilocode-%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</link><pubDate>Sun, 02 Nov 2025 15:26:10 +0800</pubDate><guid>https://svtter.cn/p/%E4%B8%80%E4%B8%AA%E5%88%92%E7%AE%97%E7%9A%84-kilocode-%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</guid><description>&lt;img src="https://svtter.cn/p/%E4%B8%80%E4%B8%AA%E5%88%92%E7%AE%97%E7%9A%84-kilocode-%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/pics/bg.png" alt="Featured image of post 一个划算的 kilocode 使用方法" /&gt;&lt;blockquote&gt;
&lt;p&gt;图片由 lovart 生成。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;众所周不知，我已经购买了 &lt;a class="link" href="https://svtter.cn/p/%E6%99%BA%E8%B0%B1-glm-4.5-%E5%9C%A8%E7%BC%96%E7%A8%8B%E6%96%B9%E9%9D%A2%E7%9A%84%E8%8B%A5%E5%B9%B2%E9%97%AE%E9%A2%98/" &gt;glm4.6 年付版本&lt;/a&gt;，但是体验下来编程能力着实一般。但是转念一想，呵，实际上可以用来读代码呀。&lt;/p&gt;
&lt;p&gt;因此使用 kilocode ask 模式用于读代码，节省了不少时间，速度还很快，也算是另一种回本。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://svtter.cn/p/%E4%B8%80%E4%B8%AA%E5%88%92%E7%AE%97%E7%9A%84-kilocode-%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/pics/blog-img.png"
width="924"
height="312"
srcset="https://svtter.cn/p/%E4%B8%80%E4%B8%AA%E5%88%92%E7%AE%97%E7%9A%84-kilocode-%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/pics/blog-img_hu_ab26343998d848de.png 480w, https://svtter.cn/p/%E4%B8%80%E4%B8%AA%E5%88%92%E7%AE%97%E7%9A%84-kilocode-%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/pics/blog-img_hu_aee8231ca3eb1da.png 1024w"
loading="lazy"
alt="ask mode"
class="gallery-image"
data-flex-grow="296"
data-flex-basis="710px"
&gt;&lt;/p&gt;
&lt;p&gt;在 ask mode 下，模型无法操作文件（偶尔也会有 kilocode 会有 bug, bug 可能导致 LLM 可以修改文件。但是近期未出现），因此不必担心 glm 瞎搞导致仓库出现问题。&lt;/p&gt;
&lt;p&gt;基于此，更进一步思考下，如果 claude code 用完了，怎么进一步 vibe coding 呢？&lt;/p&gt;
&lt;h2 id="有效利用弱模型的方法---在-ask-mode-中使用"&gt;有效利用弱模型的方法 - 在 ask mode 中使用
&lt;/h2&gt;&lt;p&gt;这就引出了我这两天尝试的一种新思路——效果很好—— &lt;a class="link" href="https://kilocode.ai/docs/basic-usage/using-modes#ask-mode" target="_blank" rel="noopener"
&gt;ask mode&lt;/a&gt; 采用 glm4.6，coding mode 采用 deepseek-chat。&lt;/p&gt;
&lt;p&gt;deepseek 能够较为严格的遵从指令，glm4.6 运行速度有保证。因此整个效率提升了。&lt;/p&gt;
&lt;p&gt;此外，由于 ask 模式下，glm4.6 可以更好的提取信息，不至于浪费。如果理解错误了，切换成 deepseek-reasoner 也不迟。&lt;/p&gt;
&lt;h3 id="关于-ask-mode"&gt;关于 Ask Mode
&lt;/h3&gt;&lt;p&gt;&lt;a class="link" href="https://kilocode.ai/docs/basic-usage/using-modes#ask-mode" target="_blank" rel="noopener"
&gt;Ask mode&lt;/a&gt; 限制了大模型对文件的操作。也就是说大模型只能 read file 但是不能 write file。&lt;/p&gt;
&lt;p&gt;通过并行读取，kilocode 可以一次性将多个文件提供给 LLM 进行代码阅读，从而加速开发者对代码进行理解。&lt;/p&gt;
&lt;p&gt;这些 ask 的内容可以作为 context 给模型。也就是说，如果你希望让模型更加了解代码，通过几次 ask，然后切换到 coding mode 来修改代码，可能会得到更好的结果。&lt;/p&gt;
&lt;h2 id="一次性达成率-once-finished-rate-ofr"&gt;一次性达成率 (Once Finished Rate, OFR)
&lt;/h2&gt;&lt;p&gt;我觉得对于一个 llm+coding agent 组合来说，一次性达成率 (OFR )至关重要。&lt;/p&gt;
&lt;p&gt;一次性达成率定义为：&lt;/p&gt;
$$ OFR = \frac{n_{f}}{N_{total}} $$&lt;p&gt;其中，$n_{f}$ 是一次性完成任务的数量，$N_{total}$是提出任务的总数量。在 coding benchmark 中，可以考虑观测 Pass@1 来衡量这个能力。&lt;/p&gt;
&lt;p&gt;也就是说，当我们提出问题的时候，coding agent 能够一次性解决问题的比例。&lt;/p&gt;
&lt;p&gt;比如 claude code + sonnet 组合，基本上是 OFR 是最高的。OFR 较高意味着用户不需要反复调试代码，只需要生成代码然后就可以投入到下一个 feature 的开发中。这是真正的高效和提效。&lt;/p&gt;
&lt;p&gt;相比之下，GLM4.6 的 OFR 可能不到其一半的程度。用户需要不停的针对生成的代码进行优化。如果使用 coding agent 本身进行优化，可能来来回回也解决不了问题。这种现象我称之为 echo（回音壁），或者中文形式“鬼打墙”。绕来绕去，仿佛不具备智能一般。如果是其他的模型，例如 deepseek，在经过几次提示之后，可以走出 echo 状态。但是 glm 不太行。&lt;/p&gt;
&lt;h3 id="为什么-glm-不行"&gt;为什么 glm 不行？
&lt;/h3&gt;&lt;p&gt;浅见：该问题是 glm 4.6 过量的使用了生成数据造成的，即模型过拟合了。这在视觉模型上较为常见——通过生成数据来拔高在某些评测指标上的性能，但却因为生成数据过多导致在实际问题上无法得到较高的性能。&lt;/p&gt;
&lt;h2 id="好文推荐ai-创造了更多的价值"&gt;好文推荐：AI 创造了更多的价值
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="link" href="https://a16z.com/the-trillion-dollar-ai-software-development-stack/" target="_blank" rel="noopener"
&gt;The Trillion Dollar AI Software Development Stack&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>Claude Code Plugin 使用体验</title><link>https://svtter.cn/p/claude-code-plugin-%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/</link><pubDate>Tue, 14 Oct 2025 10:16:54 +0800</pubDate><guid>https://svtter.cn/p/claude-code-plugin-%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/</guid><description>&lt;img src="https://svtter.cn/p/claude-code-plugin-%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/pics/bg.svg" alt="Featured image of post Claude Code Plugin 使用体验" /&gt;&lt;p&gt;总的来说，体验不佳。&lt;/p&gt;
&lt;p&gt;可能是因为刚推出的原因，总体来说不成熟。&lt;/p&gt;
&lt;p&gt;典型的几个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;有 &lt;a class="link" href="https://docs.claude.com/en/docs/claude-code/sub-agents#example-subagents" target="_blank" rel="noopener"
&gt;agents&lt;/a&gt; 不用。&lt;/li&gt;
&lt;li&gt;有 &lt;a class="link" href="https://docs.claude.com/en/docs/agents-and-tools/mcp-connector#mcp-server-configuration" target="_blank" rel="noopener"
&gt;mcp&lt;/a&gt; 不用。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;工具调用不频繁，需要自己去提醒。但是我作为用户，一般不会刻意的记有哪些 agent。&lt;/p&gt;
&lt;p&gt;更重要的是影响效率。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果使用 deepseek v3.2，因为比较短的 context 长度 （128K），deepseek 在工具以及 mcp 多的时候表现不太好。&lt;/li&gt;
&lt;li&gt;plugins 很多情况下不会提升你的工具使用体验，反而会降低。这是由于 mcp 工具和 plugins 加大了 input tokens。这使得模型不得不处理更多的 context。transformers 计算复杂度是 O(n^2)，因此长度一旦上升，造成的影响很大。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总的来说不建议现在用。&lt;/p&gt;</description></item><item><title>[过期] 我现在更多的使用 GLM 4.6 了</title><link>https://svtter.cn/p/%E8%BF%87%E6%9C%9F-%E6%88%91%E7%8E%B0%E5%9C%A8%E6%9B%B4%E5%A4%9A%E7%9A%84%E4%BD%BF%E7%94%A8-glm-4.6-%E4%BA%86/</link><pubDate>Thu, 09 Oct 2025 15:36:00 +0800</pubDate><guid>https://svtter.cn/p/%E8%BF%87%E6%9C%9F-%E6%88%91%E7%8E%B0%E5%9C%A8%E6%9B%B4%E5%A4%9A%E7%9A%84%E4%BD%BF%E7%94%A8-glm-4.6-%E4%BA%86/</guid><description>&lt;img src="https://svtter.cn/p/%E8%BF%87%E6%9C%9F-%E6%88%91%E7%8E%B0%E5%9C%A8%E6%9B%B4%E5%A4%9A%E7%9A%84%E4%BD%BF%E7%94%A8-glm-4.6-%E4%BA%86/glm-vs-deepseek.svg" alt="Featured image of post [过期] 我现在更多的使用 GLM 4.6 了" /&gt;&lt;blockquote&gt;
&lt;p&gt;updated at: 2025-10-27
只有在很简单的任务上我才会使用 glm4.6。实际体验上，经常会出现小问题。例如使用 claude code 的时候无法更新文件。&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;● Update&lt;span class="o"&gt;(&lt;/span&gt;content/post/2025-10-24-我又买了-kimi-coding-plan/pics/bg.svg&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; ⎿  Error editing file
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; ⎿  Interrupted · What should Claude &lt;span class="k"&gt;do&lt;/span&gt; instead?
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;hr&gt;
&lt;p&gt;这是近期使用 code agent 一些体会。&lt;/p&gt;
&lt;h2 id="模型对比"&gt;模型对比
&lt;/h2&gt;&lt;p&gt;在我的实际使用体验下来，相比于 DeepSeek v3.2，GLM 4.6 还是要更强一些。&lt;/p&gt;
&lt;p&gt;例如，我在 nextjs 的项目中，创建了配置 nextjs config -&amp;gt; baseUrl 192.168.2.14:8080，GLM 4.6 在不提供明确上下文的前提下，能识别这个预先配置，但是 DeepSeek v3.2 无法做到。&lt;/p&gt;
&lt;p&gt;但 GLM 4.6 并非全面领先的。在问题相对不确定的情况下，DeepSeek v3.2 更加保守，不会去突破我在任务完成时预先提出的限制。GLM 4.6 则视我的限制于无物，大胆的修改然后改崩。&lt;/p&gt;
&lt;h2 id="工具"&gt;工具
&lt;/h2&gt;&lt;p&gt;相比于在 claude code / cline 中使用 GLM 4.6，在 kilo code 中使用体验是最好的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kilo code 可以并行读取文件，cc 只能串行一个个读取&lt;/li&gt;
&lt;li&gt;kilo code 强制要求生成 plan，相比于 cc 对 big model 限制更多。&lt;/li&gt;
&lt;li&gt;可视化界面更好操作。我可以直接 ban 掉 python 命令（我需要执行 uv run 而不是直接执行 python 命令）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是 kilo code 本身也有问题。无法使用 input; http 类型的 mcpServer。这使得 web-search-prime 在 kilo code 上无法使用。&lt;/p&gt;
&lt;h2 id="相关阅读"&gt;相关阅读
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="link" href="https://atbug.com/budget-efficiency-kilo-code-choice/" target="_blank" rel="noopener"
&gt;预算有限，效率拉满：为什么 Kilo Code 成了我的首选 Coding Agent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="link" href="https://kilocode.ai/" target="_blank" rel="noopener"
&gt;kilo code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>动态切换 Provider 的 Claude Code</title><link>https://svtter.cn/p/%E5%8A%A8%E6%80%81%E5%88%87%E6%8D%A2-provider-%E7%9A%84-claude-code/</link><pubDate>Fri, 05 Sep 2025 10:05:01 +0800</pubDate><guid>https://svtter.cn/p/%E5%8A%A8%E6%80%81%E5%88%87%E6%8D%A2-provider-%E7%9A%84-claude-code/</guid><description>&lt;img src="https://svtter.cn/p/%E5%8A%A8%E6%80%81%E5%88%87%E6%8D%A2-provider-%E7%9A%84-claude-code/pics/featured_20250924_145030.png" alt="Featured image of post 动态切换 Provider 的 Claude Code" /&gt;&lt;p&gt;Claude Code 额度有 5 小时限制（20美元版本），因此如果处理一些简单的任务，通过部分便宜的 API 来做更好。&lt;/p&gt;
&lt;p&gt;我编写了一个脚本，可以完成这个事情：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt; 1
&lt;/span&gt;&lt;span class="lnt"&gt; 2
&lt;/span&gt;&lt;span class="lnt"&gt; 3
&lt;/span&gt;&lt;span class="lnt"&gt; 4
&lt;/span&gt;&lt;span class="lnt"&gt; 5
&lt;/span&gt;&lt;span class="lnt"&gt; 6
&lt;/span&gt;&lt;span class="lnt"&gt; 7
&lt;/span&gt;&lt;span class="lnt"&gt; 8
&lt;/span&gt;&lt;span class="lnt"&gt; 9
&lt;/span&gt;&lt;span class="lnt"&gt;10
&lt;/span&gt;&lt;span class="lnt"&gt;11
&lt;/span&gt;&lt;span class="lnt"&gt;12
&lt;/span&gt;&lt;span class="lnt"&gt;13
&lt;/span&gt;&lt;span class="lnt"&gt;14
&lt;/span&gt;&lt;span class="lnt"&gt;15
&lt;/span&gt;&lt;span class="lnt"&gt;16
&lt;/span&gt;&lt;span class="lnt"&gt;17
&lt;/span&gt;&lt;span class="lnt"&gt;18
&lt;/span&gt;&lt;span class="lnt"&gt;19
&lt;/span&gt;&lt;span class="lnt"&gt;20
&lt;/span&gt;&lt;span class="lnt"&gt;21
&lt;/span&gt;&lt;span class="lnt"&gt;22
&lt;/span&gt;&lt;span class="lnt"&gt;23
&lt;/span&gt;&lt;span class="lnt"&gt;24
&lt;/span&gt;&lt;span class="lnt"&gt;25
&lt;/span&gt;&lt;span class="lnt"&gt;26
&lt;/span&gt;&lt;span class="lnt"&gt;27
&lt;/span&gt;&lt;span class="lnt"&gt;28
&lt;/span&gt;&lt;span class="lnt"&gt;29
&lt;/span&gt;&lt;span class="lnt"&gt;30
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-zsh" data-lang="zsh"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;# claude --dangerously-skip-permissions&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nb"&gt;alias&lt;/span&gt; &lt;span class="nv"&gt;cc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;#34;claude&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;# Function to unset DeepSeek environment variables&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;unset_cc&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;unset&lt;/span&gt; ANTHROPIC_BASE_URL
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;unset&lt;/span&gt; ANTHROPIC_AUTH_TOKEN
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;unset&lt;/span&gt; ANTHROPIC_MODEL
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;unset&lt;/span&gt; ANTHROPIC_SMALL_FAST_MODEL
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;#34;CC environment variables unset&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;# Function to set DeepSeek environment variables&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;enable_ds&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;ANTHROPIC_BASE_URL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;https://api.deepseek.com/anthropic
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;ANTHROPIC_AUTH_TOKEN&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;DEEPSEEK_API_KEY&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;ANTHROPIC_MODEL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;deepseek-chat
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;ANTHROPIC_SMALL_FAST_MODEL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;deepseek-chat
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;#34;DeepSeek environment variables set&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;enable_kimi&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;ANTHROPIC_BASE_URL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;https://api.moonshot.cn/anthropic
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;ANTHROPIC_AUTH_TOKEN&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;MOONSHOT_API_KEY&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;ANTHROPIC_MODEL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;kimi-k2-turbo-preview
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;ANTHROPIC_SMALL_FAST_MODEL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;kimi-k2-turbo-preview
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;#34;Kimi environment variables set&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id="如何使用"&gt;如何使用
&lt;/h2&gt;&lt;p&gt;将这个脚本放在你的配置目录下。例如:&lt;code&gt;~/.config/cc.zsh&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;在你的 zsh 配置文件中，加载这个脚本: &lt;code&gt;source ~/.config/cc.zsh&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;当你需要使用&lt;code&gt;Deepseek API&lt;/code&gt;的时候，运行&lt;code&gt;enable_ds&lt;/code&gt;。如果需要使用 kimi，则运行&lt;code&gt;enable_kimi&lt;/code&gt; 即可。&lt;/p&gt;
&lt;p&gt;注意：每次打开新的 shell，都需要手动 &lt;code&gt;enable_*&lt;/code&gt;&lt;/p&gt;</description></item><item><title>How to Use Claude Code With Deepseek</title><link>https://svtter.cn/p/how-to-use-claude-code-with-deepseek/</link><pubDate>Tue, 26 Aug 2025 14:42:54 +0800</pubDate><guid>https://svtter.cn/p/how-to-use-claude-code-with-deepseek/</guid><description>&lt;img src="https://svtter.cn/p/how-to-use-claude-code-with-deepseek/pics/bg.png" alt="Featured image of post How to Use Claude Code With Deepseek" /&gt;&lt;p&gt;有时候我们无法直接使用 anthropic API。但是 Claude Code (CC) 体验非常好，我们又希望使用 CC。&lt;/p&gt;
&lt;p&gt;这个时候可以试试 deepseek 提供的 API，来使用 CC。&lt;/p&gt;
&lt;p&gt;Deepseek 已经提供了对应的接口：&lt;a class="link" href="https://api-docs.deepseek.com/zh-cn/guides/anthropic_api" target="_blank" rel="noopener"
&gt;如何使用 Claude Code + DeepSeek 的组合？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;现在主流的 llm api 有两个，一个是 openai，另一个就是 anthropic。anthropic 通过 CC 来获得了一定的话语权。&lt;/p&gt;
&lt;p&gt;如果你想更多的了解 CC 的使用场景我建议阅读 &lt;a class="link" href="https://www.anthropic.com/news/how-anthropic-teams-use-claude-code" target="_blank" rel="noopener"
&gt;Anthropic 的官方博客&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;此外，还有一些扩展资料&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class="link" href="https://mp.weixin.qq.com/s/gk0tzMxWZ-NgsUWg5iLoSg" target="_blank" rel="noopener"
&gt;https://mp.weixin.qq.com/s/gk0tzMxWZ-NgsUWg5iLoSg&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item></channel></rss>