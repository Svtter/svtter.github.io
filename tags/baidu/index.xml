<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Baidu on Svtter's Blog</title><link>https://svtter.cn/tags/baidu/</link><description>Recent content in Baidu on Svtter's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sat, 15 Feb 2025 09:50:49 +0800</lastBuildDate><atom:link href="https://svtter.cn/tags/baidu/index.xml" rel="self" type="application/rss+xml"/><item><title>实际推理模型和实验中推理模型</title><link>https://svtter.cn/p/%E5%AE%9E%E9%99%85%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%AE%9E%E9%AA%8C%E4%B8%AD%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B/</link><pubDate>Sat, 15 Feb 2025 09:50:49 +0800</pubDate><guid>https://svtter.cn/p/%E5%AE%9E%E9%99%85%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%AE%9E%E9%AA%8C%E4%B8%AD%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B/</guid><description>&lt;p>最近使用 paddlepaddle 比较多，发现了 paddleocr 对模型做了一个区分。有时候会给用户带来一些困惑。这里详细说说。&lt;/p>
&lt;p>实验中用于推理的模型，也就是可训练的模型。一般paddle的模型文件是这样的：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">-rw-r--r-- &lt;span class="m">1&lt;/span> root root 420M Feb &lt;span class="m">12&lt;/span> 15:59 model.pdopt
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">-rw-r--r-- &lt;span class="m">1&lt;/span> root root 275M Feb &lt;span class="m">12&lt;/span> 15:59 model.pdparams
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>一个是 pdopt 一个是 pdparams。&lt;/p>
&lt;p>这个就是用来在实验过程中进行推理的模型。一般用&lt;code>tools/infer_rec.py&lt;/code>。&lt;/p>
&lt;p>如果要实际部署到开发环境，需要将现在的实验中的模型做一个转换。&lt;/p>
&lt;p>需要执行&lt;code>tools/export_model.py&lt;/code>来把模型转换成&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">inference/en_PP-OCRv3_rec/
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ├── inference.pdiparams # 识别inference模型的参数文件
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> └── inference.json # 识别inference模型的program文件
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>如此一来，就可以使用 paddlex 或者其他的推理服务来推理了。&lt;/p>
&lt;h2 id="总结">总结
&lt;/h2>&lt;ul>
&lt;li>实际上国内的深度学习框架技术上并不差，只不过做的太大，也没有很好的入门教程，所以开发者本身不用。&lt;/li>
&lt;li>百度对于自己的名声维护的太差。从之前的公关老大翻车就能看出来。&lt;/li>
&lt;li>做个 python web 的类比。如果 torch 是 flask，那么 paddlepaddle 更像是 django。&lt;/li>
&lt;/ul></description></item></channel></rss>