<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Opencode on Svtter's Blog</title><link>https://svtter.cn/tags/opencode/</link><description>Recent content in Opencode on Svtter's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sat, 17 Jan 2026 22:18:33 +0800</lastBuildDate><atom:link href="https://svtter.cn/tags/opencode/index.xml" rel="self" type="application/rss+xml"/><item><title>最近发现的好工具 - opencode</title><link>https://svtter.cn/p/%E6%9C%80%E8%BF%91%E5%8F%91%E7%8E%B0%E7%9A%84%E5%A5%BD%E5%B7%A5%E5%85%B7-opencode/</link><pubDate>Sat, 17 Jan 2026 22:18:33 +0800</pubDate><guid>https://svtter.cn/p/%E6%9C%80%E8%BF%91%E5%8F%91%E7%8E%B0%E7%9A%84%E5%A5%BD%E5%B7%A5%E5%85%B7-opencode/</guid><description>&lt;p&gt;近期大量使用 opencode/claude code 组合来开发，探索了三个比较有用的工具。&lt;/p&gt;
&lt;h2 id="tmux-mcp"&gt;tmux mcp
&lt;/h2&gt;&lt;p&gt;先让 opencode 配置 Linux 环境的 tmux，然后让 opencode 安装 &lt;a class="link" href="https://github.com/rinadelph/tmux-mcp.git" target="_blank" rel="noopener"
&gt;https://github.com/rinadelph/tmux-mcp.git&lt;/a&gt; ；安装完成后即可使用 oc 来控制 tmux 的内容。&lt;/p&gt;
&lt;p&gt;可以通过这种方式来重新激活的停止的 opencode session。例如，可以开多个 tmux，然后让其中一个 opencode 通过 tmux 工具来监控，启停任务。&lt;/p&gt;
&lt;h2 id="ralph-loop"&gt;ralph-loop
&lt;/h2&gt;&lt;p&gt;这个工具可以通过 claude code 官方插件来安装，通过 &lt;code&gt;/ralph-loop:ralph-loop&lt;/code&gt; 来启动。常见的套路就是给一个任务，然后给出终止的判据。这样 claude code 每次停下就会通过 hook 重新启动，从而强迫 claude code 完成任务。&lt;/p&gt;
&lt;p&gt;这个插件的缺点是非常烧 token；如果没有 max20 订阅，还是不要订阅比较好。&lt;/p&gt;
&lt;h2 id="playwright-mcp"&gt;playwright mcp
&lt;/h2&gt;&lt;p&gt;这个插件可以启动浏览器来完成端到端测试，或者编写端到端测试代码。可以更好的形成 loop，来让 cc 或者 oc 改进代码。&lt;/p&gt;</description></item><item><title>高效省钱：我的 AI Agent 工作流选择</title><link>https://svtter.cn/p/%E9%AB%98%E6%95%88%E7%9C%81%E9%92%B1%E6%88%91%E7%9A%84-ai-agent-%E5%B7%A5%E4%BD%9C%E6%B5%81%E9%80%89%E6%8B%A9/</link><pubDate>Mon, 05 Jan 2026 16:00:00 +0800</pubDate><guid>https://svtter.cn/p/%E9%AB%98%E6%95%88%E7%9C%81%E9%92%B1%E6%88%91%E7%9A%84-ai-agent-%E5%B7%A5%E4%BD%9C%E6%B5%81%E9%80%89%E6%8B%A9/</guid><description>&lt;img src="https://svtter.cn/p/%E9%AB%98%E6%95%88%E7%9C%81%E9%92%B1%E6%88%91%E7%9A%84-ai-agent-%E5%B7%A5%E4%BD%9C%E6%B5%81%E9%80%89%E6%8B%A9/featured-image.jpg" alt="Featured image of post 高效省钱：我的 AI Agent 工作流选择" /&gt;&lt;p&gt;Claude Code 一个月 $100 费用有些高，很多朋友都有点扛不住。为了解决问题，我实践了一套工作流。&lt;/p&gt;
&lt;p&gt;模型方面，我的建议是，选择 &lt;code&gt;Gemini 3 Flash&lt;/code&gt; 的按需用量作为替代。&lt;/p&gt;
&lt;p&gt;原因：Gemini 3 Flash 性价比极高；响应速度快、处理效率高，价格仅为 Opus 和 Sonnet 的几分之一。对于大多数任务，Flash 版本已经足够使用。&lt;/p&gt;
&lt;h2 id="省钱的-workflow"&gt;省钱的 Workflow
&lt;/h2&gt;&lt;p&gt;一个经济实惠的工作流：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;制定计划&lt;/strong&gt;：使用 Gemini 3 Flash&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;执行构建&lt;/strong&gt;：使用 OpenCode 提供的免费 GLM 4.7（或 MiniMax M2.1）。亦或者你已经购买了 &lt;a class="link" href="https://svtter.cn/p/%E6%99%BA%E8%B0%B1-glm-4.5-%E5%9C%A8%E7%BC%96%E7%A8%8B%E6%96%B9%E9%9D%A2%E7%9A%84%E8%8B%A5%E5%B9%B2%E9%97%AE%E9%A2%98/" target="_blank" rel="noopener"
&gt;Zhipu Coding Plan&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;提到 Gemini 3 就不能不提 GPT-5.2。&lt;/p&gt;
&lt;p&gt;首先，部分工程师不使用 coding agent，而是使用直接使用 ChatGPT.com。这种使用方式且不论是否高效，可靠性就令人担忧。从实际体验来看，GPT-5.2 的回复语气做了拟人化微调，过于迎合用户。虽然可以调整语气，但对于专业开发者来说可能不是最佳选择。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://svtter.cn/p/%E9%AB%98%E6%95%88%E7%9C%81%E9%92%B1%E6%88%91%E7%9A%84-ai-agent-%E5%B7%A5%E4%BD%9C%E6%B5%81%E9%80%89%E6%8B%A9/pics/image_1767597061665_0.png"
width="1023"
height="930"
srcset="https://svtter.cn/p/%E9%AB%98%E6%95%88%E7%9C%81%E9%92%B1%E6%88%91%E7%9A%84-ai-agent-%E5%B7%A5%E4%BD%9C%E6%B5%81%E9%80%89%E6%8B%A9/pics/image_1767597061665_0_hu_c015f16c1d892d52.png 480w, https://svtter.cn/p/%E9%AB%98%E6%95%88%E7%9C%81%E9%92%B1%E6%88%91%E7%9A%84-ai-agent-%E5%B7%A5%E4%BD%9C%E6%B5%81%E9%80%89%E6%8B%A9/pics/image_1767597061665_0_hu_474d285f9e3620e9.png 1024w"
loading="lazy"
alt="GPT-5.2 回复语气截图"
class="gallery-image"
data-flex-grow="110"
data-flex-basis="264px"
&gt;&lt;/p&gt;
&lt;p&gt;此外，尽管 GPT-5.2 在 SWE-bench veried 上得到了较好的性能，但是我实际体验不好。这就不得不说一下 SWE-bench 的历史：&lt;/p&gt;
&lt;p&gt;SWE-bench 最初由&lt;strong&gt;普林斯顿大学&lt;/strong&gt;团队提出（ICLR 2024），用于评估语言模型解决真实 GitHub 问题的能力。&lt;/p&gt;
&lt;p&gt;但问题在于：2024年8月，OpenAI 的 Preparedness 团队与原作者合作，推出了 &lt;strong&gt;SWE-bench Verified&lt;/strong&gt;（500个经过人工验证的问题子集）。由于 OpenAI 参与了这个新版本 benchmark 的&lt;strong&gt;设计&lt;/strong&gt;，因此在这个 benchmark 下测试的 OpenAI 模型性能值得怀疑。这并不一定是主观引入性能优化，但是 Bias 在这种情况下，极有可能存在。&lt;/p&gt;
&lt;p&gt;还是那句话：从实际使用上来看，codex 总不能带来特别理想的结果。&lt;/p&gt;
&lt;h2 id="一些-opencode-技巧"&gt;一些 opencode 技巧
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;通过 OpenCode 使用 Agent&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;OpenCode 支持启动 SubAgent。调试前后端代码时，可以让 OpenCode 在不同目录启动 Agent，有效避免权限问题。&lt;/p&gt;
&lt;ol start="2"&gt;
&lt;li&gt;OpenSpec：跨 Agent 共享规范&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-fallback" data-lang="fallback"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;1. OpenCode + Gemini 3 Flash → 生成 proposal
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;2. Codex → 代码审查
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;3. Claude Code → 再次审查
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;4. OpenSpec Apply → 最终执行
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;OpenSpec 生成 spec 是靠谱的，但是有时候便宜模型代码质量不行。这个时候可以多生成几次，使用 spec 生成多次，从中挑选最好的结果。&lt;/p&gt;
&lt;p&gt;最后，如果从 PR 看到确实不行，仍可以继续采用 sonnet 4.5 来实现代码。&lt;/p&gt;
&lt;h2 id="思考"&gt;思考
&lt;/h2&gt;&lt;p&gt;作为 Agent 工程师，我们需要基于以下趋势做决策：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;模型会越来越聪明&lt;/li&gt;
&lt;li&gt;执行速度会越来越快&lt;/li&gt;
&lt;li&gt;价格会越来越便宜&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;虽然这是大趋势，但在实际任务中仍需平衡计算速度、成本和最终效果。也许很快就会出现能够自动平衡这些因素的 Agent 系统，但是现阶段考虑这些问题，没错。&lt;/p&gt;</description></item></channel></rss>