<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Paddlepaddle on Svtter's Blog</title><link>https://svtter.cn/tags/paddlepaddle/</link><description>Recent content in Paddlepaddle on Svtter's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Mon, 14 Apr 2025 18:11:00 +0800</lastBuildDate><atom:link href="https://svtter.cn/tags/paddlepaddle/index.xml" rel="self" type="application/rss+xml"/><item><title>Knowledge of PPOCR.md</title><link>https://svtter.cn/p/knowledge-of-ppocr.md/</link><pubDate>Mon, 14 Apr 2025 18:11:00 +0800</pubDate><guid>https://svtter.cn/p/knowledge-of-ppocr.md/</guid><description>&lt;img src="https://svtter.cn/p/knowledge-of-ppocr.md/background.jpg" alt="Featured image of post Knowledge of PPOCR.md" /&gt;&lt;p&gt;我在 2.7 版本中使用的 ppocrlabel 组件，被迁移到了单独的 &lt;a class="link" href="https://github.com/PFCCLab/PPOCRLabel" target="_blank" rel="noopener"
&gt;PPOCRLabel&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id="ppocrlabel"&gt;PPOCRLabel
&lt;/h2&gt;&lt;p&gt;可以通过 ppocrlabel 组件，使用模型对图像进行预标记，然后在手动进行自主标记。&lt;/p&gt;
&lt;p&gt;这种方式可以极大的降低标注的成本。&lt;/p&gt;
&lt;p&gt;关于 &lt;a class="link" href="" &gt;paddleocr&lt;/a&gt; 的知识，以后都会在这个博客下面更新。&lt;/p&gt;
&lt;p&gt;在部署 paddle 的时候遇到了一些问题，这里记录一下。&lt;/p&gt;
&lt;h2 id="notebook-related"&gt;Notebook Related
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;我使用镜像&lt;code&gt;registry.baidubce.com/paddlepaddle/paddle:2.4.2&lt;/code&gt;，安装&lt;code&gt;notebook&lt;/code&gt;，无法打开:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src="https://svtter.cn/p/knowledge-of-ppocr.md/pics/paddle-note-error.png"
width="1832"
height="414"
srcset="https://svtter.cn/p/knowledge-of-ppocr.md/pics/paddle-note-error_hu_c106deaf2249524f.png 480w, https://svtter.cn/p/knowledge-of-ppocr.md/pics/paddle-note-error_hu_a87e63bcde44b288.png 1024w"
loading="lazy"
alt="error"
class="gallery-image"
data-flex-grow="442"
data-flex-basis="1062px"
&gt;&lt;/p&gt;
&lt;ol start="2"&gt;
&lt;li&gt;paddle:2.4 以上的版本，如果 CPU 不支持 AVX，那么是无法运行的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我尝试部署了一个 paddle 模型，最后通过使用&lt;code&gt;PaddleOCR&lt;/code&gt;这个类完成了推理。其他的方法推理都不太行。&lt;/p&gt;
&lt;p&gt;实际上 paddle 在 ocr 方面做的很出色了，兼顾了很多细节。&lt;/p&gt;
&lt;p&gt;但是,由于文档使用的工具链上有不够细致的地方，导致用户不太舒服。&lt;/p&gt;</description></item><item><title>实际推理模型和实验中推理模型</title><link>https://svtter.cn/p/%E5%AE%9E%E9%99%85%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%AE%9E%E9%AA%8C%E4%B8%AD%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B/</link><pubDate>Sat, 15 Feb 2025 09:50:49 +0800</pubDate><guid>https://svtter.cn/p/%E5%AE%9E%E9%99%85%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%AE%9E%E9%AA%8C%E4%B8%AD%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B/</guid><description>&lt;p&gt;最近使用 paddlepaddle 比较多，发现了 paddleocr 对模型做了一个区分。有时候会给用户带来一些困惑。这里详细说说。&lt;/p&gt;
&lt;p&gt;实验中用于推理的模型，也就是可训练的模型。一般paddle的模型文件是这样的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;-rw-r--r-- &lt;span class="m"&gt;1&lt;/span&gt; root root 420M Feb &lt;span class="m"&gt;12&lt;/span&gt; 15:59 model.pdopt
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;-rw-r--r-- &lt;span class="m"&gt;1&lt;/span&gt; root root 275M Feb &lt;span class="m"&gt;12&lt;/span&gt; 15:59 model.pdparams
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;一个是 pdopt 一个是 pdparams。&lt;/p&gt;
&lt;p&gt;这个就是用来在实验过程中进行推理的模型。一般用&lt;code&gt;tools/infer_rec.py&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;如果要实际部署到开发环境，需要将现在的实验中的模型做一个转换。&lt;/p&gt;
&lt;p&gt;需要执行&lt;code&gt;tools/export_model.py&lt;/code&gt;来把模型转换成&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-fallback" data-lang="fallback"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;inference/en_PP-OCRv3_rec/
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; ├── inference.pdiparams # 识别inference模型的参数文件
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; └── inference.json # 识别inference模型的program文件
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;如此一来，就可以使用 paddlex 或者其他的推理服务来推理了。&lt;/p&gt;
&lt;h2 id="总结"&gt;总结
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;实际上国内的深度学习框架技术上并不差，只不过做的太大，也没有很好的入门教程，所以开发者本身不用。&lt;/li&gt;
&lt;li&gt;百度对于自己的名声维护的太差。从之前的公关老大翻车就能看出来。&lt;/li&gt;
&lt;li&gt;做个 python web 的类比。如果 torch 是 flask，那么 paddlepaddle 更像是 django。&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>Cuda and Paddle.md</title><link>https://svtter.cn/p/cuda-and-paddle.md/</link><pubDate>Tue, 11 Feb 2025 15:41:18 +0800</pubDate><guid>https://svtter.cn/p/cuda-and-paddle.md/</guid><description>&lt;p&gt;深度学习环境配置是很多朋友迈不过去的坎。不过有了大模型，遇到问题定位的速度能快很多。&lt;/p&gt;
&lt;p&gt;我花了一些时间去适配老版本的 paddle，搞定了，这里发一篇文章记录一下。&lt;/p&gt;
&lt;p&gt;docker image 里面，很多 cuda11 镜像，在 cuda12 的环境下是跑不起来的。原因我也不太清楚。这个时候，可以选择大版本一致的 cuda。&lt;/p&gt;
&lt;p&gt;为了保证不影响 server 其他人的环境，不要更新 nvidia 驱动，安装自己的 cuda 版本，然后修改环境变量，就能改变系统的 cuda。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bashrc" data-lang="bashrc"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;# CUDA_VERSION=11.7&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;CUDA_HOME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;#34;/usr/local/cuda-&lt;/span&gt;&lt;span class="nv"&gt;$CUDA_VERSION&lt;/span&gt;&lt;span class="s2"&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;#34;&lt;/span&gt;&lt;span class="nv"&gt;$CUDA_HOME&lt;/span&gt;&lt;span class="s2"&gt;/lib64:&lt;/span&gt;&lt;span class="nv"&gt;$LD_LIBRARY_PATH&lt;/span&gt;&lt;span class="s2"&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$CUDA_HOME&lt;/span&gt;/bin:&lt;span class="nv"&gt;$PATH&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;应用这个环境变量，然后查看&lt;code&gt;nvidia-smi&lt;/code&gt;，就能看到版本的变化。&lt;/p&gt;</description></item></channel></rss>