<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Paddlepaddle on Svtter's Blog</title><link>https://svtter.cn/tags/paddlepaddle/</link><description>Recent content in Paddlepaddle on Svtter's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Mon, 14 Apr 2025 18:11:00 +0800</lastBuildDate><atom:link href="https://svtter.cn/tags/paddlepaddle/index.xml" rel="self" type="application/rss+xml"/><item><title>Knowledge of PPOCR.md</title><link>https://svtter.cn/p/knowledge-of-ppocr.md/</link><pubDate>Mon, 14 Apr 2025 18:11:00 +0800</pubDate><guid>https://svtter.cn/p/knowledge-of-ppocr.md/</guid><description>&lt;p>我在 2.7 版本中使用的 ppocrlabel 组件，被迁移到了单独的 &lt;a class="link" href="https://github.com/PFCCLab/PPOCRLabel" target="_blank" rel="noopener"
>PPOCRLabel&lt;/a>。&lt;/p>
&lt;p>可以通过 ppocrlabel 组件，使用模型对图像进行预标记，然后在手动进行自主标记。&lt;/p>
&lt;p>这种方式可以极大的降低标注的成本。&lt;/p>
&lt;p>关于 &lt;a class="link" href="" >paddleocr&lt;/a> 的知识，以后都会在这个博客下面更新。&lt;/p></description></item><item><title>实际推理模型和实验中推理模型</title><link>https://svtter.cn/p/%E5%AE%9E%E9%99%85%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%AE%9E%E9%AA%8C%E4%B8%AD%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B/</link><pubDate>Sat, 15 Feb 2025 09:50:49 +0800</pubDate><guid>https://svtter.cn/p/%E5%AE%9E%E9%99%85%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%AE%9E%E9%AA%8C%E4%B8%AD%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B/</guid><description>&lt;p>最近使用 paddlepaddle 比较多，发现了 paddleocr 对模型做了一个区分。有时候会给用户带来一些困惑。这里详细说说。&lt;/p>
&lt;p>实验中用于推理的模型，也就是可训练的模型。一般paddle的模型文件是这样的：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">-rw-r--r-- &lt;span class="m">1&lt;/span> root root 420M Feb &lt;span class="m">12&lt;/span> 15:59 model.pdopt
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">-rw-r--r-- &lt;span class="m">1&lt;/span> root root 275M Feb &lt;span class="m">12&lt;/span> 15:59 model.pdparams
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>一个是 pdopt 一个是 pdparams。&lt;/p>
&lt;p>这个就是用来在实验过程中进行推理的模型。一般用&lt;code>tools/infer_rec.py&lt;/code>。&lt;/p>
&lt;p>如果要实际部署到开发环境，需要将现在的实验中的模型做一个转换。&lt;/p>
&lt;p>需要执行&lt;code>tools/export_model.py&lt;/code>来把模型转换成&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">inference/en_PP-OCRv3_rec/
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ├── inference.pdiparams # 识别inference模型的参数文件
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> └── inference.json # 识别inference模型的program文件
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>如此一来，就可以使用 paddlex 或者其他的推理服务来推理了。&lt;/p>
&lt;h2 id="总结">总结
&lt;/h2>&lt;ul>
&lt;li>实际上国内的深度学习框架技术上并不差，只不过做的太大，也没有很好的入门教程，所以开发者本身不用。&lt;/li>
&lt;li>百度对于自己的名声维护的太差。从之前的公关老大翻车就能看出来。&lt;/li>
&lt;li>做个 python web 的类比。如果 torch 是 flask，那么 paddlepaddle 更像是 django。&lt;/li>
&lt;/ul></description></item><item><title>Cuda and Paddle.md</title><link>https://svtter.cn/p/cuda-and-paddle.md/</link><pubDate>Tue, 11 Feb 2025 15:41:18 +0800</pubDate><guid>https://svtter.cn/p/cuda-and-paddle.md/</guid><description>&lt;p>深度学习环境配置是很多朋友迈不过去的坎。不过有了大模型，遇到问题定位的速度能快很多。&lt;/p>
&lt;p>我花了一些时间去适配老版本的 paddle，搞定了，这里发一篇文章记录一下。&lt;/p>
&lt;p>docker image 里面，很多 cuda11 镜像，在 cuda12 的环境下是跑不起来的。原因我也不太清楚。这个时候，可以选择大版本一致的 cuda。&lt;/p>
&lt;p>为了保证不影响 server 其他人的环境，不要更新 nvidia 驱动，安装自己的 cuda 版本，然后修改环境变量，就能改变系统的 cuda。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bashrc" data-lang="bashrc">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># CUDA_VERSION=11.7&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">CUDA_HOME&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;/usr/local/cuda-&lt;/span>&lt;span class="nv">$CUDA_VERSION&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">LD_LIBRARY_PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="nv">$CUDA_HOME&lt;/span>&lt;span class="s2">/lib64:&lt;/span>&lt;span class="nv">$LD_LIBRARY_PATH&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$CUDA_HOME&lt;/span>/bin:&lt;span class="nv">$PATH&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>应用这个环境变量，然后查看&lt;code>nvidia-smi&lt;/code>，就能看到版本的变化。&lt;/p></description></item></channel></rss>