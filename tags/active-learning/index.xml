<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Active Learning on Svtter's Blog</title><link>https://svtter.cn/tags/active-learning/</link><description>Recent content in Active Learning on Svtter's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Tue, 20 Nov 2018 01:00:00 +0800</lastBuildDate><atom:link href="https://svtter.cn/tags/active-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>使用主动学习加速机器学习</title><link>https://svtter.cn/p/%E4%BD%BF%E7%94%A8%E4%B8%BB%E5%8A%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link><pubDate>Tue, 20 Nov 2018 01:00:00 +0800</pubDate><guid>https://svtter.cn/p/%E4%BD%BF%E7%94%A8%E4%B8%BB%E5%8A%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</guid><description>&lt;blockquote class="wp-block-quote">
&lt;p>
一篇 medium 文章的渣翻
&lt;/p>
&lt;p>&lt;cite>&lt;a class="link" href="https://becominghuman.ai/accelerate-machine-learning-with-active-learning-96cea4b72fdb" target="_blank" rel="noopener"
>https://becominghuman.ai/accelerate-machine-learning-with-active-learning-96cea4b72fdb&lt;/a>&lt;/cite>&lt;/p>
&lt;/blockquote>
&lt;p>让我们讨论一下主动学习。我相信这个方法可以极大的增速，以及减少许多机器学习工程的花费。这篇文章我将从两个部分说明这个问题。在第一部分，我给出了一个极高的层级的主动学习的说明，以及如何把它利用到机器学习工程中。在第二部分，深入到一个主动学习 demo 中。&lt;/p>
&lt;h2 id="第一部分">第一部分
&lt;/h2>&lt;h3 id="主动学习是如何工作的">主动学习是如何工作的
&lt;/h3>&lt;p>让我们通过一个很简单的概览，来看看机器学习是如何工作地。&lt;figure class="wp-block-image">&lt;/p>
&lt;p>&lt;img src="https://i2.wp.com/ww1.sinaimg.cn/large/c53b1907ly1fxdd3awts2j218g0j4wj2.jpg?w=625" alt="Repeat thousands of times and you get a trained model!" data-recalc-dims="1" />&lt;/figure>&lt;/p>
&lt;p>许多机器学习模型是巨大的猜疑机器——他们看了许多数据，计算出一个猜测的结果，检查他们的答案，微调一下，然后再试试。在许多数据之后，模型将会变得十分准确。&lt;/p>
&lt;h3 id="标记数据">标记数据
&lt;/h3>&lt;p>…&lt;/p>
&lt;h3 id="主动学习">主动学习
&lt;/h3>&lt;p>主动学习是一种方法，有时可以极大减少标记样本的数量。它通过专家标记样本来完成这个工作。&lt;/p>
&lt;p>不使用全部的数据一次标注所有数据，主动学习优先处理那些让模型感到困惑的数据，并且仅仅需要好那些数据的标签。模型在小样本数据上进行训练，然后根据那些最令模型疑惑的数据，请求更多的标签。&lt;/p>
&lt;p>通过优先处理那些最迷惑的样本，模型可以专注于提供一些最有价值的信息。这帮助模型训练的更快，并且让专家跳过那些对于模型帮助不是很大的数据。结果是，我们可以很大程度上减少标记样本的数量，并且我们仍然得到一个很好的模型。这意味着节省时间和金钱！&lt;/p>
&lt;h2 id="第二部分">第二部分
&lt;/h2>&lt;h3 id="mnist-例子">MNIST 例子
&lt;/h3>&lt;p>让我们看一下实际的主动学习样本。&lt;/p>
&lt;p>使用文档良好的 MNIST 数据集，以及经典的 Tensorflow 卷积神经完了过。一个聪明的模型和架构可以做的更好，但是我们想要直接使用这个模型。&lt;/p>
&lt;p>MNIST 数据集是公开可获取得的数据集，包含了大量的手写数字，以及数值标签。它经常被使用于机器学习入门教程，因为他的标记数据质量很高，并且简单地模型也可以表现的不错。&lt;figure class="wp-block-image">&lt;/p>
&lt;p>&lt;img src="https://i1.wp.com/ww1.sinaimg.cn/large/c53b1907ly1fxdd4dewm6j20ho04fq38.jpg?w=625" alt="" data-recalc-dims="1" />&lt;/figure>&lt;/p>
&lt;h3 id="设计">设计
&lt;/h3>&lt;p>这个工程包含两个部分：&lt;/p>
&lt;ol>
&lt;li>在训练模型的时候，模仿主动学习&lt;/li>
&lt;li>在严格的模型上确定主动学习的效率&lt;/li>
&lt;/ol>
&lt;h3 id="训练一个模型">训练一个模型
&lt;/h3>&lt;p>我们使用 mini-batch 训练。这个模型仅仅在训练集中，看一个小数量样本，通过小数量样本进行学习。&lt;/p>
&lt;p>这里，我们可以看到一个正常的（非 – 主动学习）的训练过程，模型在一个随机结合的小批次上进行训练。每在小 – 批次训练中的迭代，都在测试记上运行模型（不作为训练集的一部分）来追踪模型是怎样增长的。我提供了准确率以及 cross-entropy 损失（就像是平均误差一样）。在这里，每一个小批次有个 10 个例子，我运行了 2000 批次（20000 个标注）。&lt;figure class="wp-block-image">&lt;/p>
&lt;p>&lt;img src="https://i1.wp.com/ww1.sinaimg.cn/large/c53b1907ly1fxdd4pv3b2j218g0fhjtx.jpg?w=625" alt="" data-recalc-dims="1" />&lt;/figure>&lt;/p>
&lt;p>对于这个分类任务，我们试图把 0~9 的数字进行分类，意味着随机猜测仅有 10% 的准确率。简单的神经网络已经做的不错了。&lt;/p>
&lt;h3 id="模拟主动学习">模拟主动学习
&lt;/h3>&lt;p>获得主动学习结果有一点小技巧。我们不在数据集中的随机选择数据，相反，模型将会评估许多在训练集中的例子，然后将置信度最小的数据作为小 – 批次（在这个工程中，我查看了 1000 个在训练集中的随机样本，来确定置信度至少为 10）。在那里，模型将会像处理小 – 批次数据一样处理进行训练过程，它将会重复这个过程来更新模型。就像是在 “非 – 主动学习” 样例中，每经过一些迭代，我将会在测试记上运行模型，追踪模型的训练过程。&lt;figure class="wp-block-image">&lt;/p>
&lt;p>&lt;img src="https://i2.wp.com/ww1.sinaimg.cn/large/c53b1907ly1fxdd5z4a18j218g0ljjwd.jpg?w=625" alt="" data-recalc-dims="1" />&lt;/figure>&lt;/p>
&lt;p>有许多很好的文章来说明如何实现 主动学习。在这里，我仅仅想要把事情做的简单一些。这个模型使用一个 “softmax” 来生成概率——在这个例子中，是数字 0~9。” 置信度” 通过选择” 最大的概率减去最小的概率 “。模型越自信，这个差值越大。（置信度不意味着准确率）。&lt;figure class="wp-block-image">&lt;/p>
&lt;p>&lt;img src="https://i0.wp.com/ww1.sinaimg.cn/large/c53b1907ly1fxdd96i561j218g0ejte0.jpg?w=625" alt="" data-recalc-dims="1" />&lt;/figure>&lt;/p>
&lt;p>主动学习过程，使用了那些置信度比较低的数据，并且在上面进行训练。并且当然的，当模型改变了，它的置信度也一样会改变。&lt;/p>
&lt;p>MNIST 数据集已经有了我们需要的标签，但是这个过程，在 mini-batch 中，模拟询问了专家，来获取标签。在通常情况下，专家会随机被提问，来获取数据。在主动学习的例子中，模型会选择那些数据，希望专家进行标注。&lt;/p>
&lt;p>让我们来看一下主动学习结果 VS 一般的结果。注意 y-axis。&lt;figure class="wp-block-image">&lt;/p>
&lt;p>&lt;img src="https://i1.wp.com/ww1.sinaimg.cn/large/c53b1907ly1fxddharrn6j218g0h378k.jpg?w=625" alt="" data-recalc-dims="1" />&lt;/figure>&lt;/p>
&lt;p>通过 mini-batch（8000 标签），主动学习的方法匹配了 2000 mini-batch（20000label）数据的准确率。所以，使用一接近一半的数据，主动学习可以达到同样地准确率。&lt;/p>
&lt;h3 id="倾斜数据的二分类任务">倾斜数据的二分类任务
&lt;/h3>&lt;p>主动学习可以大施拳脚的地方是，数据的强烈偏差。&lt;/p>
&lt;p>训练一个模型的时候，重要的不仅仅是标记的数据，还有不同数据的，合理的不同表示。如果我们尝试在 MNIST 上训练一个模型，而没有任何包含 3 的数据，收集多少数据并不重要，重要的是我们的模型不可能区分 3。如果我们仅仅含有一小部分 3，我们仍然会面临一个问题，就是模型仅仅会准确的区分其他数字，也就是那些有更好表达的数据。&lt;/p>
&lt;p>数据的偏差，不均衡对于 MNIST 数据集中不存在，但是它的确是一个真实世界的问题。如果我们训练一个模型来识别 CT 中的脑瘤，大多数 CT 图像不会含有肿瘤图像，所以标注 “肿瘤” 的数据将会远不均衡于 “非肿瘤” 的样本数据。因为主动学习优先考虑的例子不那么自信，因此主动学习可能有助于识别 “异常 “或代表性不足的数据并且确定优先级。&lt;/p>
&lt;p>我们在 MNIST 上模拟一下 skew 的问题。重新定义 MNIST 的问题，定义成 3 或者非 3，然后，非 3 的数据有 90%，而 3 的数据仅有 10%。所以愚蠢的策略将会在” 非 3“上达到 90% 的准确率，让我们看一下主动学习是如何做的：&lt;figure class="wp-block-image">&lt;/p>
&lt;p>&lt;img src="https://i2.wp.com/ww1.sinaimg.cn/large/c53b1907ly1fxdf9177f8j218g0hdwkb.jpg?w=625" alt="" data-recalc-dims="1" />&lt;/figure>&lt;/p>
&lt;p>在使用主动学习的时候，在 500mini-batch（5000labels）我们就达到，甚至更好地准确率。相比之下，cross-entropy 算法，通过 2000 mini-batch。主动学习减少了 4 倍的数据量。主动学习是如何做到的？看下图。&lt;figure class="wp-block-image">&lt;/p>
&lt;p>&lt;img src="https://i2.wp.com/ww1.sinaimg.cn/large/c53b1907ly1fxdfe5ahvnj20ua0nkjv0.jpg?w=625" alt="" data-recalc-dims="1" />&lt;/figure>&lt;/p>
&lt;h2 id="后续">后续
&lt;/h2>&lt;p>未完，后面翻不翻看心情。。也不知道工业界玩 active learning 的多不多。&lt;/p></description></item></channel></rss>