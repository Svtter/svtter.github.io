<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Keras on Svtter&#39;s Blog</title>
    <link>https://svtter.github.io/tags/keras/</link>
    <description>Recent content in Keras on Svtter&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 07 Jan 2019 01:00:00 +0800</lastBuildDate><atom:link href="https://svtter.github.io/tags/keras/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>My Keras tricks</title>
      <link>https://svtter.github.io/2019/01/07/my-keras-tricks/</link>
      <pubDate>Mon, 07 Jan 2019 01:00:00 +0800</pubDate>
      
      <guid>https://svtter.github.io/2019/01/07/my-keras-tricks/</guid>
      <description>&lt;p&gt;记录了一些使用 keras 的技巧。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Keras坑</title>
      <link>https://svtter.github.io/2018/02/01/keras%E5%9D%91/</link>
      <pubDate>Thu, 01 Feb 2018 01:00:00 +0800</pubDate>
      
      <guid>https://svtter.github.io/2018/02/01/keras%E5%9D%91/</guid>
      <description>使用Keras做分类的时候踩了一个坑，也是拿来主义的锅，估计也有不少同志遇到。
在进行分类的时候，往往使用categorical_crossentropy，有时候萌新（像我）会用binary_crossentropy，虽然结果可能上浮30%，但是这个结果是不对的。model.fit以及model.evaluate给出的acc的值都是有问题的，正确的计算方法应该是：
# Actual accuracy calculated manually: y_pred = model.predict(x_test) acc = sum([np.argmax(y_test[i])==np.argmax(y_pred[i]) for i in range(10000)])/10000 其中
numpy.argmax(a, axis=None, out=None) # 返回沿轴axis最大值的索引。 使用测试样本的数量代替10000，输出的acc才是正确的结果。
这个方法是使用二分类的时候才能使用的，label的个数多于2就不能使用。
参考 https://stackoverflow.com/questions/42081257/keras-binary-crossentropy-vs-categorical-crossentropy-performance</description>
    </item>
    
  </channel>
</rss>
